{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shuntaro0628/Optimization_Project.git\n",
        "%cd /content/Optimization_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zHGbB44dU3X",
        "outputId": "f5e58927-f8e7-4aef-e2ca-28365c052775"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Optimization_Project'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n",
            "/content/Optimization_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iZN2u5WKRFqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dec8d11-a452-4c29-ef1f-c4aacc774394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2e7acc0cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torch import nn \n",
        "from torch import sigmoid\n",
        "from torch import atan\n",
        "from torch import tanh\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "seed = 7777\n",
        "random.seed(seed) \n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bse1wsKN1NxY"
      },
      "outputs": [],
      "source": [
        "lpx_min = 50 #mm\n",
        "lpx_max = 650 #mm\n",
        "lpy_min = 50 #mm\n",
        "lpy_max = 2050 #mm\n",
        "wp_min = 25 # mm\n",
        "wp_max = 325 # mm\n",
        "a_min = 0 # mm\n",
        "a_max = 200 # mm\n",
        "p_min = 0 # mm\n",
        "p_max = 200 # mm\n",
        "ls_min = 50 # mm\n",
        "ls_max = 450 # mm\n",
        "ws_min = 25 # mm\n",
        "ws_max = 225 # mm\n",
        "Ip_min = 50 # A rms\n",
        "Ip_max = 200 # A rms\n",
        "Np_min = 4 #turn\n",
        "Np_max = 10 #turn\n",
        "Ns_min = 4 #turn\n",
        "Ns_max = 10 #turn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B-TMPJtCKIM6"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module): # Design your model using class\n",
        "    def __init__(self):    \n",
        "        super(Model, self).__init__() #In the constructor, we instantiate nn.Linear module.\n",
        "        self.linear1 = nn.Linear(12, 100, bias=True).cuda() # nn.Linear(<input size> ,<output size>)\n",
        "        self.linear2 = nn.Linear(100, 100, bias=True).cuda()\n",
        "        self.linear3 = nn.Linear(100, 42, bias=True).cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = atan(self.linear1(x))\n",
        "        x = atan(self.linear2(x))\n",
        "        x = atan(self.linear2(x))\n",
        "        y_pred = self.linear3(x)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g9oqBtYCRR_c"
      },
      "outputs": [],
      "source": [
        "model = Model() # our model\n",
        "model.load_state_dict(torch.load('saved_model_state.pt'))\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dMoXnTFV8U1P"
      },
      "outputs": [],
      "source": [
        "def generate_noise(a, b):\n",
        "    low,high = -1, 1  # range of uniform distribution\n",
        "\n",
        "    return torch.distributions.uniform.Uniform(low,high).sample([a,b]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z9cggAl1BGHo"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import activation\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_length: int): \n",
        "      super(Generator, self).__init__() \n",
        "      self.dense_layer = nn.Linear(int(input_length), 128).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer.weight) \n",
        "      self.bn1 = nn.BatchNorm1d(128).cuda()\n",
        "      self.dense_layer1 = nn.Linear(128, 256).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer1.weight) \n",
        "      self.bn2 = nn.BatchNorm1d(256).cuda()\n",
        "      self.dense_layer2 = nn.Linear(256, 512).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer2.weight) \n",
        "      self.bn3 = nn.BatchNorm1d(512).cuda()\n",
        "      self.dense_layer3 = nn.Linear(512, 256).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer3.weight) \n",
        "      self.bn4 = nn.BatchNorm1d(256).cuda()\n",
        "      self.dense_layer4 = nn.Linear(256, 128).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer4.weight) \n",
        "      self.bn5 = nn.BatchNorm1d(128).cuda()\n",
        "      self.dense_layer5 = nn.Linear(128, int(input_length)).cuda() \n",
        "      torch.nn.init.kaiming_uniform_(self.dense_layer5.weight) \n",
        "      self.activation = nn.Sigmoid() \n",
        "\n",
        "    def forward(self, x): \n",
        "      x = atan(self.bn1(self.dense_layer(x)))\n",
        "      x = atan(self.bn2(self.dense_layer1(x)))\n",
        "      x = atan(self.bn3(self.dense_layer2(x)))\n",
        "      x = atan(self.bn4(self.dense_layer3(x))) \n",
        "      x = atan(self.bn5(self.dense_layer4(x))) \n",
        "      x = self.activation(self.dense_layer5(x)) \n",
        "      return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vuPxzX7KuP2l"
      },
      "outputs": [],
      "source": [
        "generator = Generator(10)\n",
        "for param in generator.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lmtwMfOB20K4"
      },
      "outputs": [],
      "source": [
        "def scaler(value, min , max):\n",
        "    return value * (max - min) + min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "brlwMfzj1Nxh"
      },
      "outputs": [],
      "source": [
        "@torch.jit.script\n",
        "def linspace(start: torch.Tensor, stop: torch.Tensor, num: int):\n",
        "    \"\"\"\n",
        "    Creates a tensor of shape [num, *start.shape] whose values are evenly spaced from start to end, inclusive.\n",
        "    Replicates but the multi-dimensional bahaviour of numpy.linspace in PyTorch.\n",
        "    \"\"\"\n",
        "    # create a tensor of 'num' steps from 0 to 1\n",
        "    steps = torch.arange(num, dtype=torch.float32, device=start.device) / (num - 1)\n",
        "    \n",
        "    # reshape the 'steps' tensor to [-1, *([1]*start.ndim)] to allow for broadcastings\n",
        "    # - using 'steps.reshape([-1, *([1]*start.ndim)])' would be nice here but torchscript\n",
        "    #   \"cannot statically infer the expected size of a list in this contex\", hence the code below\n",
        "    for i in range(start.ndim):\n",
        "        steps = steps.unsqueeze(-1)\n",
        "    \n",
        "    # the output starts at 'start' and increments until 'stop' in each dimension\n",
        "    out = start[None] + steps*(stop - start)[None]\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xloGE25R8Jtm"
      },
      "outputs": [],
      "source": [
        "def scale_and_extract(arr):\n",
        "    # scaler_min = torch.tensor([50., 50., 25., 0., 0., 50., 25.,50.,4.,4.], requires_grad=True, device=\"cuda\")\n",
        "    # scaler_max = torch.tensor([2050., 650., 325., 200., 200., 450., 225.,200.,10.,10.], requires_grad=True, device=\"cuda\")\n",
        "\n",
        "    scaler_min = torch.tensor([0., 50., 50., 0., 50., 0., 25.,50.,4.,4.], requires_grad=True, device=\"cuda\")\n",
        "    scaler_max = torch.tensor([200., 650., 2050., 450., 200., 325., 225.,200.,10.,10.], requires_grad=True, device=\"cuda\")\n",
        "    \n",
        "    arr = scaler(arr, scaler_min, scaler_max)\n",
        "    y0_i = (arr[:,2] + arr[:,5]) / 2\n",
        "    y1_i = (3/2 * arr[:,2]) + (5/2 * arr[:,5]) + (2 * arr[:,0]) + (arr[:,4])\n",
        "\n",
        "    ys_min = (y1_i)\n",
        "    ys_max = (y1_i + (y1_i - y0_i) / 2)\n",
        "    \n",
        "    ys = linspace(ys_min, ys_max, num = 5)\n",
        "    ys = torch.transpose(ys, 0, 1)\n",
        "    arr[:,8:10] = torch.round(arr[:,8:10])\n",
        "    temp = torch.cat([arr, ys], axis=1)\n",
        "    return temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7be3y_pG1Nxj"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "TRAINING = 3000\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "\n",
        "#optimizer = torch.optim.Adam(generator.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kdiffs = []\n",
        "coil_losses = []"
      ],
      "metadata": {
        "id": "bJ5XlCKA8wem"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "f = 85*10**3 #[Hz]\n",
        "w =2*math.pi*f #[rad/s]\n",
        "Pout=50000 #W\n",
        "Vdc = 400 #800 # V\n",
        "Vbat = 400 #V\n",
        "QCoil = 400\n",
        "b = 50"
      ],
      "metadata": {
        "id": "jai09uo6e1OC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = generate_noise(10000, 10)\n",
        "GP = generator(noise)\n",
        "scaled_array = scale_and_extract(GP)\n",
        "gp_parameters = torch.cat([scaled_array[:,0:7],scaled_array[:,10:15]],axis=1)\n",
        "extra_parameters = scaled_array[:,7:10]\n",
        "print(extra_parameters)\n",
        "MP = model(scaled_array[:,0:12])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44TlTSnclCKs",
        "outputId": "b4fcebb0-4699-4da3-ec70-037779835dda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[175.6591,   6.0000,   7.0000],\n",
            "        [ 80.7429,   9.0000,   9.0000],\n",
            "        [ 57.5141,   9.0000,   7.0000],\n",
            "        ...,\n",
            "        [ 91.8971,   8.0000,   9.0000],\n",
            "        [ 82.6505,   9.0000,   8.0000],\n",
            "        [162.1917,   5.0000,   5.0000]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max(x_sample, x, axis=0):# axis=0 is vertical direction.\n",
        "    min_x = x_sample.min(axis=axis, keepdims=True)\n",
        "    max_x = x_sample.max(axis=axis, keepdims=True)\n",
        "    x = (x-min_x.values)/(max_x.values-min_x.values)\n",
        "    print(x)\n",
        "\n",
        "def inv_min_max(x_sample, x_std, axis=0):\n",
        "    min_x = x_sample.min(axis=axis, keepdims=True)\n",
        "    max_x = x_sample.max(axis=axis, keepdims=True)\n",
        "    x = x_std*(max_x.values-min_x.values)+min_x.values\n"
      ],
      "metadata": {
        "id": "pwzB6jd3h2Mo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foldername ='/content/Optimization_Project/' \n",
        "filename1 = 'DWPT_v5_N10'\n",
        "filename2 = 'DWPT_v5_N100'\n",
        "filename3 = 'DWPT_v5_N200'\n",
        "filename4 = 'DWPT_v5_N300'\n",
        "filename5 = 'DWPT_v5_N400'\n",
        "df1 = pd.read_csv(foldername+filename1+'_after.csv')\n",
        "df2 = pd.read_csv(foldername+filename2+'_after.csv')\n",
        "df3 = pd.read_csv(foldername+filename3+'_after.csv')\n",
        "df4 = pd.read_csv(foldername+filename4+'_after.csv')\n",
        "df5 = pd.read_csv(foldername+filename5+'_after.csv')\n",
        "df = pd.concat([df1,df2,df3,df4,df5],axis=0)"
      ],
      "metadata": {
        "id": "jkTrlAJMH5UO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['Unnamed: 0']"
      ],
      "metadata": {
        "id": "D-5NaDsCdyiu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXzpQf5O1Nxk",
        "outputId": "774d93d3-1e39-4b91-bacb-aa324150638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0 | Coupling: 13.138%\n",
            "Epoch:    0 | Coil Loss: 2879.691\n",
            "Epoch:    0 | Bstray: 138.118\n",
            "Epoch:    0 | Pave: 361.350\n",
            "Epoch:    0 | V_PriCore: 9.411\n",
            "Epoch:    0 | V_SecCore: 51.435\n",
            "Epoch:    0 | V_PriWind: 386.671\n",
            "Epoch:    0 | V_SecWind: 1.131\n",
            "Epoch:  100 | Coupling: 13.042%\n",
            "Epoch:  100 | Coil Loss: 1255.191\n",
            "Epoch:  100 | Bstray: 52.212\n",
            "Epoch:  100 | Pave: 388.276\n",
            "Epoch:  100 | V_PriCore: 9.967\n",
            "Epoch:  100 | V_SecCore: 51.823\n",
            "Epoch:  100 | V_PriWind: 411.098\n",
            "Epoch:  100 | V_SecWind: 1.456\n",
            "Epoch:  200 | Coupling: 10.110%\n",
            "Epoch:  200 | Coil Loss: 878.772\n",
            "Epoch:  200 | Bstray: 61.392\n",
            "Epoch:  200 | Pave: 312.284\n",
            "Epoch:  200 | V_PriCore: 10.280\n",
            "Epoch:  200 | V_SecCore: 52.466\n",
            "Epoch:  200 | V_PriWind: 500.314\n",
            "Epoch:  200 | V_SecWind: 1.917\n",
            "Epoch:  300 | Coupling: 7.783%\n",
            "Epoch:  300 | Coil Loss: 595.804\n",
            "Epoch:  300 | Bstray: 60.729\n",
            "Epoch:  300 | Pave: 236.628\n",
            "Epoch:  300 | V_PriCore: 9.873\n",
            "Epoch:  300 | V_SecCore: 52.746\n",
            "Epoch:  300 | V_PriWind: 632.750\n",
            "Epoch:  300 | V_SecWind: 2.156\n",
            "Epoch:  400 | Coupling: 7.493%\n",
            "Epoch:  400 | Coil Loss: 559.231\n",
            "Epoch:  400 | Bstray: 64.613\n",
            "Epoch:  400 | Pave: 249.349\n",
            "Epoch:  400 | V_PriCore: 9.611\n",
            "Epoch:  400 | V_SecCore: 52.853\n",
            "Epoch:  400 | V_PriWind: 665.963\n",
            "Epoch:  400 | V_SecWind: 2.227\n",
            "Epoch:  500 | Coupling: 7.109%\n",
            "Epoch:  500 | Coil Loss: 529.218\n",
            "Epoch:  500 | Bstray: 74.514\n",
            "Epoch:  500 | Pave: 268.269\n",
            "Epoch:  500 | V_PriCore: 9.901\n",
            "Epoch:  500 | V_SecCore: 52.935\n",
            "Epoch:  500 | V_PriWind: 709.319\n",
            "Epoch:  500 | V_SecWind: 2.279\n",
            "Epoch:  600 | Coupling: 6.931%\n",
            "Epoch:  600 | Coil Loss: 529.909\n",
            "Epoch:  600 | Bstray: 75.488\n",
            "Epoch:  600 | Pave: 278.697\n",
            "Epoch:  600 | V_PriCore: 9.708\n",
            "Epoch:  600 | V_SecCore: 52.977\n",
            "Epoch:  600 | V_PriWind: 726.762\n",
            "Epoch:  600 | V_SecWind: 2.313\n",
            "Epoch:  700 | Coupling: 6.849%\n",
            "Epoch:  700 | Coil Loss: 532.638\n",
            "Epoch:  700 | Bstray: 75.051\n",
            "Epoch:  700 | Pave: 284.812\n",
            "Epoch:  700 | V_PriCore: 9.517\n",
            "Epoch:  700 | V_SecCore: 52.995\n",
            "Epoch:  700 | V_PriWind: 735.848\n",
            "Epoch:  700 | V_SecWind: 2.330\n",
            "Epoch:  800 | Coupling: 6.789%\n",
            "Epoch:  800 | Coil Loss: 535.086\n",
            "Epoch:  800 | Bstray: 74.626\n",
            "Epoch:  800 | Pave: 289.130\n",
            "Epoch:  800 | V_PriCore: 9.373\n",
            "Epoch:  800 | V_SecCore: 53.007\n",
            "Epoch:  800 | V_PriWind: 741.958\n",
            "Epoch:  800 | V_SecWind: 2.347\n",
            "Epoch:  900 | Coupling: 6.762%\n",
            "Epoch:  900 | Coil Loss: 535.421\n",
            "Epoch:  900 | Bstray: 74.544\n",
            "Epoch:  900 | Pave: 290.000\n",
            "Epoch:  900 | V_PriCore: 9.365\n",
            "Epoch:  900 | V_SecCore: 53.015\n",
            "Epoch:  900 | V_PriWind: 742.014\n",
            "Epoch:  900 | V_SecWind: 2.350\n",
            "Epoch: 1000 | Coupling: 6.758%\n",
            "Epoch: 1000 | Coil Loss: 535.500\n",
            "Epoch: 1000 | Bstray: 74.766\n",
            "Epoch: 1000 | Pave: 290.962\n",
            "Epoch: 1000 | V_PriCore: 9.391\n",
            "Epoch: 1000 | V_SecCore: 53.021\n",
            "Epoch: 1000 | V_PriWind: 742.169\n",
            "Epoch: 1000 | V_SecWind: 2.349\n",
            "Epoch: 1100 | Coupling: 6.759%\n",
            "Epoch: 1100 | Coil Loss: 535.583\n",
            "Epoch: 1100 | Bstray: 75.156\n",
            "Epoch: 1100 | Pave: 291.542\n",
            "Epoch: 1100 | V_PriCore: 9.453\n",
            "Epoch: 1100 | V_SecCore: 53.025\n",
            "Epoch: 1100 | V_PriWind: 741.611\n",
            "Epoch: 1100 | V_SecWind: 2.347\n",
            "Epoch: 1200 | Coupling: 6.724%\n",
            "Epoch: 1200 | Coil Loss: 536.074\n",
            "Epoch: 1200 | Bstray: 74.977\n",
            "Epoch: 1200 | Pave: 292.104\n",
            "Epoch: 1200 | V_PriCore: 9.371\n",
            "Epoch: 1200 | V_SecCore: 53.027\n",
            "Epoch: 1200 | V_PriWind: 743.995\n",
            "Epoch: 1200 | V_SecWind: 2.342\n",
            "Epoch: 1300 | Coupling: 6.742%\n",
            "Epoch: 1300 | Coil Loss: 535.003\n",
            "Epoch: 1300 | Bstray: 75.165\n",
            "Epoch: 1300 | Pave: 291.499\n",
            "Epoch: 1300 | V_PriCore: 9.457\n",
            "Epoch: 1300 | V_SecCore: 53.031\n",
            "Epoch: 1300 | V_PriWind: 740.883\n",
            "Epoch: 1300 | V_SecWind: 2.343\n",
            "Epoch: 1400 | Coupling: 6.720%\n",
            "Epoch: 1400 | Coil Loss: 535.281\n",
            "Epoch: 1400 | Bstray: 75.062\n",
            "Epoch: 1400 | Pave: 291.939\n",
            "Epoch: 1400 | V_PriCore: 9.422\n",
            "Epoch: 1400 | V_SecCore: 53.032\n",
            "Epoch: 1400 | V_PriWind: 742.321\n",
            "Epoch: 1400 | V_SecWind: 2.344\n",
            "Epoch: 1500 | Coupling: 6.715%\n",
            "Epoch: 1500 | Coil Loss: 535.522\n",
            "Epoch: 1500 | Bstray: 75.027\n",
            "Epoch: 1500 | Pave: 292.193\n",
            "Epoch: 1500 | V_PriCore: 9.418\n",
            "Epoch: 1500 | V_SecCore: 53.034\n",
            "Epoch: 1500 | V_PriWind: 742.772\n",
            "Epoch: 1500 | V_SecWind: 2.340\n",
            "Epoch: 1600 | Coupling: 6.712%\n",
            "Epoch: 1600 | Coil Loss: 535.253\n",
            "Epoch: 1600 | Bstray: 75.132\n",
            "Epoch: 1600 | Pave: 291.812\n",
            "Epoch: 1600 | V_PriCore: 9.424\n",
            "Epoch: 1600 | V_SecCore: 53.035\n",
            "Epoch: 1600 | V_PriWind: 742.263\n",
            "Epoch: 1600 | V_SecWind: 2.344\n"
          ]
        }
      ],
      "source": [
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for i in range(TRAINING):\n",
        "\n",
        "    for param in generator.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "    noise = generate_noise(10000, 10) #IP, Ns and Np\n",
        "    GP = generator(noise)\n",
        "\n",
        "    scaled_array = scale_and_extract(GP)\n",
        "\n",
        "    gp_parameters = torch.cat([scaled_array[:,0:7],scaled_array[:,10:15]],axis=1)\n",
        "\n",
        "    x = df.values[:,0:12]\n",
        "    #temp_gp = gp_parameters.clone()\n",
        "    x = torch.tensor(x, dtype = torch.float, requires_grad=True).cuda()\n",
        "\n",
        "    min_x = torch.min(x, dim = 0, keepdim=True).values\n",
        "    max_x = torch.max(x, dim = 0, keepdim=True).values\n",
        "\n",
        "    #value * (max - min) + min\n",
        "    gp_parameters = (gp_parameters.clone()-min_x)/(max_x-min_x)\n",
        "    # print(gp_parameters)\n",
        "    #gp_parameters = gp_parameters.clone()*(max_x-min_x) + min_x\n",
        "    extra_parameters = scaled_array[:, 7:10] #Ip, Np, Ns\n",
        "\n",
        "    # print(gp_parameters[0])\n",
        "    # print(min_x)\n",
        "    # print(max_x)\n",
        "    # break\n",
        "    MP = model(gp_parameters)\n",
        "    # y_df = df.loc[:, 'k0mm_ys0':]\n",
        "    # print(y_df.columns)\n",
        "\n",
        "    # y = torch.tensor(y_df.values, dtype=torch.float).cuda()\n",
        "\n",
        "    # min_x = y.min(axis=0, keepdims=True)\n",
        "    # max_x = y.max(axis=0, keepdims=True)\n",
        "    # MP = MP*(max_x.values-min_x.values)+min_x.values\n",
        "    # print(MP)\n",
        "    y_df = df.loc[:, 'k0mm_ys0':]\n",
        "\n",
        "    y = y_df.values\n",
        "    y = torch.tensor(y, dtype = torch.float, requires_grad=True).cuda()\n",
        "\n",
        "    min_y = torch.min(y, dim = 0).values\n",
        "    max_y = torch.max(y, dim = 0).values\n",
        "\n",
        "    MP = (MP.clone()*(max_y-min_y)).clone() + min_y\n",
        "    #print(MP[0], GP[0])\n",
        "    #calculate Is \n",
        "    kdiff = MP[:, 0].clone() - MP[:, 5].clone()\n",
        "    kdiff = abs(kdiff / MP[:, 0].clone())\n",
        "    kdiff = torch.mean(kdiff) # + scaling factor * Bstray Loss \n",
        "    kdiffs.append(kdiff.detach().cpu().item())\n",
        "    #kdiff.backward()\n",
        "    #print(MP[:,11]) # LS0MM_YSO\n",
        "    #First consider only Bstray \n",
        "    # optimizer.step()\n",
        "    #print(MP[:,6]) #LP0MM_YS0\n",
        "\n",
        "    #1/(lpy_i+2*wp_i+2*a_i+p_i)\n",
        "    # num_inverters = 1/(temp_gp[:,2]+2*temp_gp[:,5]+2*temp_gp[:,0]+temp_gp[:,4])*10**3\n",
        "\n",
        "    # sum_ = torch.mean(num_inverters)\n",
        "    # min_x = torch.min(torch.tensor(y_df.values, dtype=torch.float), dim=0).values.cuda()\n",
        "    # max_x = torch.max(torch.tensor(y_df.values, dtype=torch.float), dim=0).values.cuda()\n",
        "\n",
        "\n",
        "    MP[:,6] = MP[:,6].clone() * extra_parameters[:,1].clone()**2  # LP0MM_YSO\n",
        "    MP[:,7] = MP[:,7].clone() * extra_parameters[:,1].clone()**2  # LP0MM_YS1\n",
        "    MP[:,8] = MP[:,8].clone() * extra_parameters[:,1].clone()**2  # LP0MM_YS2\n",
        "    MP[:,9] = MP[:,9].clone() * extra_parameters[:,1].clone()**2  # LP0MM_YS3\n",
        "    MP[:,10] = MP[:,10].clone() * extra_parameters[:,1].clone()**2 # LP0MM_YS4\n",
        "\n",
        "    MP[:,11] = MP[:,11].clone() * extra_parameters[:,2].clone()**2 # LS0MM_YSO\n",
        "    MP[:,12] = MP[:,12].clone() * extra_parameters[:,2].clone()**2 # LS0MM_YS1\n",
        "    MP[:,13] = MP[:,13].clone() * extra_parameters[:,2].clone()**2 # LS0MM_YS2\n",
        "    MP[:,14] = MP[:,14].clone() * extra_parameters[:,2].clone()**2 # LS0MM_YS3\n",
        "    MP[:,15] = MP[:,15].clone() * extra_parameters[:,2].clone()**2 # LS0MM_YS4\n",
        "\n",
        "    n1_i = math.pi*w*MP[:,6]*10**(-9)*extra_parameters[:,0]*math.sqrt(2)/(4*Vdc)\n",
        "    t1 = (math.pi)**2*w*(MP[:,6]*10**(-9)*MP[:,11] *10**(-9))**0.5\n",
        "    t2 = Pout/(8*MP[:,0]*n1_i*Vdc*Vbat)\n",
        "    #print(t1, t2)\n",
        "    n2_i = t1*t2\n",
        "    #print(n2_i)\n",
        "    Is_i = 4*n2_i*Vbat/(math.pi*w*MP[:,11]*10**(-9))/math.sqrt(2)\n",
        "\n",
        "    coil_loss = w*MP[:,6]*10**(-9)*extra_parameters[:,0]**2/QCoil + w*MP[:,11] *10**(-9)*Is_i**2/QCoil\n",
        "\n",
        "    bx = (((MP[:, 30]*extra_parameters[:, 0]*extra_parameters[:, 1]) + (MP[:, 36]*Is_i*extra_parameters[:, 2]))**2 + ((MP[:, 33]*extra_parameters[:, 0]*extra_parameters[:, 1]) + (MP[:, 39]*Is_i*extra_parameters[:, 2]))**2)**0.5\n",
        "\n",
        "    by = (((MP[:, 31]*extra_parameters[:, 0]*extra_parameters[:, 1]) + (MP[:, 37]*Is_i*extra_parameters[:, 2]))**2 + ((MP[:, 34]*extra_parameters[:, 0]*extra_parameters[:, 1]) + (MP[:, 40]*Is_i*extra_parameters[:, 2]))**2)**0.5\n",
        "\n",
        "    bz = (((MP[:, 32]*extra_parameters[:, 0]*extra_parameters[:, 1])+ (MP[:, 38]*Is_i*extra_parameters[:, 2]))**2 + ((MP[:, 35]*extra_parameters[:, 0]*extra_parameters[:, 1]) + (MP[:, 41]*Is_i*extra_parameters[:, 2]))**2)**0.5\n",
        "\n",
        "    bstray = ((bx**2 + by**2 + bz**2)**0.5)\n",
        "\n",
        "    p0 = w*MP[:,0]*(MP[:,6]*10**(-9))*(MP[:,11]*10**(-9))**0.5*extra_parameters[:,0]*Is_i\n",
        "    p1 = w*MP[:,1]*(MP[:,7]*10**(-9))*(MP[:,12]*10**(-9))**0.5*extra_parameters[:,0]*Is_i  \n",
        "    p2 = w*MP[:,2]*(MP[:,8]*10**(-9))*(MP[:,13]*10**(-9))**0.5*extra_parameters[:,0]*Is_i \n",
        "    p3 = w*MP[:,3]*(MP[:,9]*10**(-9))*(MP[:,14]*10**(-9))**0.5*extra_parameters[:,0]*Is_i\n",
        "    p4 = w*MP[:,4]*(MP[:,10]*10**(-9))*(MP[:,15]*10**(-9))**0.5*extra_parameters[:,0]*Is_i \n",
        "    pave = (p0+(2*p1)+(2*p2)+(2*p3)+(2*abs(p4)))/8 \n",
        "\n",
        "    V_PriCore = (gp_parameters[:,2] +2*gp_parameters[:,5]+2*gp_parameters[:,0])*(gp_parameters[:,1]+2*gp_parameters[:,5]+2*gp_parameters[:,0])*5/(10**3) # cm3\n",
        "    V_SecCore = (gp_parameters[:,3]+2*gp_parameters[:,6]+2*b)**2*5/(10**3) # cm3\n",
        "\n",
        "    V_PriWind = (2*(gp_parameters[:,1]+gp_parameters[:,5])+2*(gp_parameters[:,2]+gp_parameters[:,5]))*6.6*6.6/(10**3)*extra_parameters[:,1]\n",
        "    V_SecWind = 4*(gp_parameters[:,3]+gp_parameters[:,6])*6.6*6.6/(10**3)*extra_parameters[:,2]\n",
        "\n",
        "    V_PriWind_ave = V_PriWind/(gp_parameters[:,2]+2*gp_parameters[:,5]+2*gp_parameters[:,0]+gp_parameters[:,4])*10**3 # cm3/m\n",
        "    V_PriCore_ave = V_PriCore/(gp_parameters[:,2]+2*gp_parameters[:,5]+2*gp_parameters[:,0]+gp_parameters[:,4])*10**3 # cm3/m\n",
        "\n",
        "    mean_V_PriCore_ave = torch.mean(V_PriCore_ave)\n",
        "    mean_V_SecCore = torch.mean(V_SecCore)\n",
        "    mean_V_PriWind_ave = torch.mean(V_PriWind_ave)\n",
        "    mean_V_SecWind = torch.mean(V_SecWind)\n",
        "\n",
        "    mean_coil_loss = torch.mean(coil_loss)\n",
        "    mean_bstray = torch.mean(bstray)\n",
        "    mean_pave = torch.mean(pave)\n",
        "    coil_losses.append(mean_coil_loss.detach().cpu().item())\n",
        "    # combined_loss = mean_coil_loss + kdiff + mean_bstray - mean_pave - mean_V_PriWind - mean_V_SecWind - mean_V_PriCore - mean_V_SecCore\n",
        "    combined_loss = mean_coil_loss + kdiff + mean_bstray - mean_pave\n",
        "    combined_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch: {i:4d} | Coupling: {100 * kdiff.item():.3f}%\")\n",
        "        print(f\"Epoch: {i:4d} | Coil Loss: {mean_coil_loss.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | Bstray: {mean_bstray.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | Pave: {mean_pave.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | V_PriCore: {mean_V_PriCore_ave.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | V_SecCore: {mean_V_SecCore.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | V_PriWind: {mean_V_PriWind_ave.item():.3f}\")\n",
        "        print(f\"Epoch: {i:4d} | V_SecWind: {mean_V_SecWind.item():.3f}\")\n",
        "        #print(f\"Epoch: {i:4d} | Inverter: {sum_.item():.3f}\")\n",
        "        \n",
        "    # scaler_min = torch.tensor([0., 50., 50., 0., 50., 0., 25.,50.,4.,4.], requires_grad=True, device=\"cuda\")\n",
        "    # scaler_max = torch.tensor([200., 650., 2050., 450., 200., 325., 225.,200.,10.,10.], requires_grad=True, device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "p0 = w*MP[:,0]*(MP[:,6]*10**(-9)*MP[:,11]*10**(-9))**0.5*extra_parameters[:,0]*Is_i\n",
        "p1 = w*MP[:,1]*(MP[:,7]*10**(-9)*MP[:,12]*10**(-9))**0.5*extra_parameters[:,0]*Is_i  \n",
        "p2 = w*MP[:,2]*(MP[:,8]*10**(-9)*MP[:,13]*10**(-9))**0.5*extra_parameters[:,0]*Is_i \n",
        "p3 = w*MP[:,3]*(MP[:,9]*10**(-9)*MP[:,14]*10**(-9))**0.5*extra_parameters[:,0]*Is_i \n",
        "p4 = w*MP[:,4]*(MP[:,10]*10**(-9)*MP[:,15]*10**(-9))**0.5*extra_parameters[:,0]*Is_i \n",
        "pave = (p0+2*p1+2*p2+2*p3+2*abs(p4))/8 \n",
        "\n",
        "b = 50\n",
        "\n",
        "V_PriCore = (gp_parameters[:,2] +2*gp_parameters[:,5]+2*gp_parameters[:,0])*(gp_parameters[:,1]+2*gp_parameters[:,5]+2*gp_parameters[:,0])*5/(10**3) # cm3\n",
        "V_SecCore = (gp_parameters[:,3]+2*gp_parameters[:,6]+2*b)**2*5/(10**3) # cm3\n",
        "\n",
        "V_PriWind = (2*(gp_parameters[:,1]+gp_parameters[:,5])+2*(gp_parameters[:,2]+gp_parameters[:,5]))*6.6*6.6/(10**3)*extra_parameters[:,1]\n",
        "V_SecWind = 4*(gp_parameters[:,3]+gp_parameters[:,6])*6.6*6.6/(10**3)*extra_parameters[:,2]\n",
        "\n",
        "V_PriWind_ave = V_PriWind/(gp_parameters[:,2]+2*gp_parameters[:,5]+2*gp_parameters[:,0]+gp_parameters[:,4])*10**3 # cm3/m\n",
        "\n",
        "V_PriCore_ave = V_PriCore/(gp_parameters[:,2]+2*gp_parameters[:,5]+2*gp_parameters[:,0]+gp_parameters[:,4])*10**3 # cm3/m\n"
      ],
      "metadata": {
        "id": "rnlTvc6htjs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  noise = generate_noise(10000, 10) #IP, Ns and Np\n",
        "  GP = generator(noise)\n",
        "\n",
        "  scaled_array = scale_and_extract(GP)\n",
        "\n",
        "  gp_parameters = torch.cat([scaled_array[:,0:7],scaled_array[:,10:15]],axis=1)\n",
        "  temp_gp = gp_parameters.clone()\n",
        "  x = df.values[:,0:12]\n",
        "\n",
        "  x = torch.tensor(x, dtype = torch.float, requires_grad=True).cuda()\n",
        "\n",
        "  min_x = torch.min(x, dim = 0, keepdim=True).values\n",
        "  max_x = torch.max(x, dim = 0, keepdim=True).values\n",
        "\n",
        "  #value * (max - min) + min\n",
        "  gp_parameters = (gp_parameters.clone()-min_x)/(max_x-min_x)\n",
        "  print(gp_parameters)\n",
        "  #gp_parameters = gp_parameters.clone()*(max_x-min_x) + min_x\n",
        "  extra_parameters = scaled_array[:, 7:10] #Ip, Np, Ns\n",
        "  MP = model(gp_parameters)\n",
        "  # y_df = df.loc[:, 'k0mm_ys0':]\n",
        "  # print(y_df.columns)\n",
        "\n",
        "  # y = torch.tensor(y_df.values, dtype=torch.float).cuda()\n",
        "\n",
        "  # min_x = y.min(axis=0, keepdims=True)\n",
        "  # max_x = y.max(axis=0, keepdims=True)\n",
        "  # MP = MP*(max_x.values-min_x.values)+min_x.values\n",
        "  # print(MP)\n",
        "  y_df = df.loc[:, 'k0mm_ys0':]\n",
        "\n",
        "  y = y_df.values\n",
        "  y = torch.tensor(y, dtype = torch.float, requires_grad=True).cuda()\n",
        "\n",
        "  min_y = torch.min(y, dim = 0).values\n",
        "  max_y = torch.max(y, dim = 0).values\n",
        "\n",
        "  MP = (MP.clone()*(max_y-min_y)).clone() + min_y\n",
        "\n",
        "  print(MP[0])\n",
        "  # print(noise[0], noise[9000])\n",
        "  # print(GP[0], GP[9000])\n",
        "  # print(MP[1], MP[9000])"
      ],
      "metadata": {
        "id": "FTPh7hkoamcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_x_final=pd.DataFrame(temp_gp.detach().cpu().numpy(), columns=['a[mm]', 'lpx[mm]', 'lpy[mm]', 'ls[mm]',\\\n",
        "  'p[mm]', 'wp[mm]', 'ws[mm]', 'ys0[mm]', 'ys1[mm]', 'ys2[mm]', 'ys3[mm]', 'ys4[mm]'])\n",
        "\n",
        "cls=['k0mm_ys0','k0mm_ys1', 'k0mm_ys2', 'k0mm_ys3', 'k0mm_ys4', 'k100mm_ys0',\\\n",
        " 'Lp0mm_ys0[nH]', 'Lp0mm_ys1[nH]', 'Lp0mm_ys2[nH]', 'Lp0mm_ys3[nH]', 'Lp0mm_ys4[nH]',\\\n",
        " 'Ls0mm_ys0[nH]', 'Ls0mm_ys1[nH]', 'Ls0mm_ys2[nH]', 'Ls0mm_ys3[nH]',\\\n",
        " 'Ls0mm_ys4[nH]', 'Lp100mm_ys0[nH]', 'Ls100mm_ys0[nH]', 'Bx_p0mm0deg[uT]',\\\n",
        " 'By_p0mm0deg[uT]', 'Bz_p0mm0deg[uT]', 'Bx_p0mm90deg[uT]', 'By_p0mm90deg[uT]',\\\n",
        " 'Bz_p0mm90deg[uT]', 'Bx_s0mm0deg[uT]', 'By_s0mm0deg[uT]', 'Bz_s0mm0deg[uT]',\\\n",
        " 'Bx_s0mm90deg[uT]', 'By_s0mm90deg[uT]', 'Bz_s0mm90deg[uT]',\\\n",
        " 'Bx_p100mm0deg[uT]', 'By_p100mm0deg[uT]', 'Bz_p100mm0deg[uT]',\\\n",
        " 'Bx_p100mm90deg[uT]', 'By_p100mm90deg[uT]', 'Bz_p100mm90deg[uT]',\\\n",
        " 'Bx_s100mm0deg[uT]', 'By_s100mm0deg[uT]', 'Bz_s100mm0deg[uT]',\\\n",
        " 'Bx_s100mm90deg[uT]', 'By_s100mm90deg[uT]', 'Bz_s100mm90deg[uT]']\n",
        "df_y_pred=pd.DataFrame(MP.detach().cpu().numpy(), columns=cls)\n",
        "\n"
      ],
      "metadata": {
        "id": "GAm8xle2apNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_I_N = pd.DataFrame(extra_parameters[:,0].detach().cpu().numpy(), columns = ['Ip[A(rms)]'])"
      ],
      "metadata": {
        "id": "VKhZd-H8bjQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_turn_N = pd.DataFrame(extra_parameters[:,1:].detach().cpu().numpy(), columns = ['Np[turn]','Ns[turn]'])"
      ],
      "metadata": {
        "id": "W-xbrC8wis5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.concat([df_I_N, df_turn_N, df_x_final, df_y_pred],axis=1)"
      ],
      "metadata": {
        "id": "qXchdZY5jD4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred"
      ],
      "metadata": {
        "id": "gv1U9iwLjM4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate B field from prediction\n",
        "N = 10000\n",
        "df_pred = pd.concat([df_I_N, df_turn_N, df_x_final, df_y_pred],axis=1)\n",
        "Bx_p0mm0deg =[]\n",
        "By_p0mm0deg =[]\n",
        "Bz_p0mm0deg =[]\n",
        "\n",
        "Bx_p0mm90deg =[]\n",
        "By_p0mm90deg =[]\n",
        "Bz_p0mm90deg =[]\n",
        "\n",
        "Bx_p100mm0deg =[]\n",
        "By_p100mm0deg =[]\n",
        "Bz_p100mm0deg =[]\n",
        "\n",
        "Bx_p100mm90deg =[]\n",
        "By_p100mm90deg =[]\n",
        "Bz_p100mm90deg =[]\n",
        "\n",
        "Bx_s0mm0deg =[]\n",
        "By_s0mm0deg =[]\n",
        "Bz_s0mm0deg =[]\n",
        "\n",
        "Bx_s0mm90deg =[]\n",
        "By_s0mm90deg =[]\n",
        "Bz_s0mm90deg =[]\n",
        "\n",
        "Bx_s100mm0deg =[]\n",
        "By_s100mm0deg =[]\n",
        "Bz_s100mm0deg =[]\n",
        "\n",
        "Bx_s100mm90deg =[]\n",
        "By_s100mm90deg =[]\n",
        "Bz_s100mm90deg =[]\n",
        "\n",
        "import math\n",
        "f = 85*10**3 #[Hz]\n",
        "w =2*math.pi*f #[rad/s]\n",
        "Pout=50000 #W\n",
        "Vdc = 400 #800 # V\n",
        "Vbat = 400 #V\n",
        "Ip =[]\n",
        "Is =[]\n",
        "VLp = []\n",
        "VLs = []\n",
        "Np =[]\n",
        "Ns =[]\n",
        "Lp0mm_ys0=[]\n",
        "Lp0mm_ys1=[]\n",
        "Lp0mm_ys2=[]\n",
        "Lp0mm_ys3=[]\n",
        "Lp0mm_ys4=[]\n",
        "Ls0mm_ys0=[]\n",
        "Ls0mm_ys1=[]\n",
        "Ls0mm_ys2=[]\n",
        "Ls0mm_ys3=[]\n",
        "Ls0mm_ys4=[]\n",
        "Lp100mm_ys0=[]\n",
        "Ls100mm_ys0=[]\n",
        "k0mm_ys0=[]\n",
        "k0mm_ys1=[]\n",
        "k0mm_ys2=[]\n",
        "k0mm_ys3=[]\n",
        "k0mm_ys4=[]\n",
        "k100mm_ys0=[]\n",
        "kdiff=[]\n",
        "Pdiff = []\n",
        "\n",
        "df_Is = pd.DataFrame(index=[], columns = ['Is[A(rms)]'])\n",
        "for i in range(len(df_pred.loc[:, 'Bx_p0mm0deg[uT]'])):\n",
        "  Bx_p0mm0deg.append(df_pred.loc[i, 'Bx_p0mm0deg[uT]']) #0-Peak\n",
        "  By_p0mm0deg.append(df_pred.loc[i, 'By_p0mm0deg[uT]'])\n",
        "  Bz_p0mm0deg.append(df_pred.loc[i, 'Bz_p0mm0deg[uT]'])\n",
        "\n",
        "  Bx_p0mm90deg.append(df_pred.loc[i, 'Bx_p0mm90deg[uT]'])\n",
        "  By_p0mm90deg.append(df_pred.loc[i, 'By_p0mm90deg[uT]'])\n",
        "  Bz_p0mm90deg.append(df_pred.loc[i, 'Bz_p0mm90deg[uT]'])\n",
        "\n",
        "  Bx_p100mm0deg.append(df_pred.loc[i, 'Bx_p100mm0deg[uT]'])\n",
        "  By_p100mm0deg.append(df_pred.loc[i, 'By_p100mm0deg[uT]'])\n",
        "  Bz_p100mm0deg.append(df_pred.loc[i, 'Bz_p100mm0deg[uT]'])\n",
        "\n",
        "  Bx_p100mm90deg.append(df_pred.loc[i, 'Bx_p100mm90deg[uT]'])\n",
        "  By_p100mm90deg.append(df_pred.loc[i, 'By_p100mm90deg[uT]'])\n",
        "  Bz_p100mm90deg.append(df_pred.loc[i, 'Bz_p100mm90deg[uT]'])\n",
        "\n",
        "  Bx_s0mm0deg.append(df_pred.loc[i, 'Bx_s0mm0deg[uT]'])\n",
        "  By_s0mm0deg.append(df_pred.loc[i, 'By_s0mm0deg[uT]'])\n",
        "  Bz_s0mm0deg.append(df_pred.loc[i, 'Bz_s0mm0deg[uT]'])\n",
        "\n",
        "  Bx_s0mm90deg.append(df_pred.loc[i, 'Bx_s0mm90deg[uT]'])\n",
        "  By_s0mm90deg.append(df_pred.loc[i, 'By_s0mm90deg[uT]'])\n",
        "  Bz_s0mm90deg.append(df_pred.loc[i, 'Bz_s0mm90deg[uT]'])\n",
        "\n",
        "  Bx_s100mm0deg.append(df_pred.loc[i, 'Bx_s100mm0deg[uT]'])\n",
        "  By_s100mm0deg.append(df_pred.loc[i, 'By_s100mm0deg[uT]'])\n",
        "  Bz_s100mm0deg.append(df_pred.loc[i, 'Bz_s100mm0deg[uT]'])\n",
        "\n",
        "  Bx_s100mm90deg.append(df_pred.loc[i, 'Bx_s100mm90deg[uT]'])\n",
        "  By_s100mm90deg.append(df_pred.loc[i, 'By_s100mm90deg[uT]'])\n",
        "  Bz_s100mm90deg.append(df_pred.loc[i, 'Bz_s100mm90deg[uT]'])\n",
        "\n",
        "  Np.append(df_turn_N.loc[i, 'Np[turn]'])\n",
        "  Ns.append(df_turn_N.loc[i, 'Ns[turn]'])  \n",
        "\n",
        "  Lp0mm_ys0.append(df_pred.loc[i, 'Lp0mm_ys0[nH]']*df_turn_N.loc[i, 'Np[turn]']**2)# The datatype is list.\n",
        "  Lp0mm_ys1.append(df_pred.loc[i, 'Lp0mm_ys1[nH]']*df_turn_N.loc[i, 'Np[turn]']**2) # nH\n",
        "  Lp0mm_ys2.append(df_pred.loc[i, 'Lp0mm_ys2[nH]']*df_turn_N.loc[i, 'Np[turn]']**2)\n",
        "  Lp0mm_ys3.append(df_pred.loc[i, 'Lp0mm_ys3[nH]']*df_turn_N.loc[i, 'Np[turn]']**2)\n",
        "  Lp0mm_ys4.append(df_pred.loc[i, 'Lp0mm_ys4[nH]']*df_turn_N.loc[i, 'Np[turn]']**2)\n",
        "  \n",
        "  Ls0mm_ys0.append(df_pred.loc[i, 'Ls0mm_ys0[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2)\n",
        "  Ls0mm_ys1.append(df_pred.loc[i, 'Ls0mm_ys1[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2)\n",
        "  Ls0mm_ys2.append(df_pred.loc[i, 'Ls0mm_ys2[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2)\n",
        "  Ls0mm_ys3.append(df_pred.loc[i, 'Ls0mm_ys3[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2)\n",
        "  Ls0mm_ys4.append(df_pred.loc[i, 'Ls0mm_ys4[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2)\n",
        "  \n",
        "  Lp100mm_ys0.append(df_pred.loc[i, 'Lp100mm_ys0[nH]']*df_turn_N.loc[i, 'Np[turn]']**2)\n",
        "  Ls100mm_ys0.append(df_pred.loc[i, 'Ls100mm_ys0[nH]']*df_turn_N.loc[i, 'Ns[turn]']**2) \n",
        "  \n",
        "  k0mm_ys0.append(df_pred.loc[i, 'k0mm_ys0'])\n",
        "  k0mm_ys1.append(df_pred.loc[i, 'k0mm_ys1'])\n",
        "  k0mm_ys2.append(df_pred.loc[i, 'k0mm_ys2'])\n",
        "  k0mm_ys3.append(df_pred.loc[i, 'k0mm_ys3'])\n",
        "  k0mm_ys4.append(df_pred.loc[i, 'k0mm_ys4'])    \n",
        "  k100mm_ys0.append(df_pred.loc[i, 'k100mm_ys0'])  \n",
        "\n",
        "  Ip.append(df_I_N.loc[i,'Ip[A(rms)]']) #A(rms)\n",
        "\n",
        "  if i % 1000 ==0:\n",
        "   print(f'Calculating Is... {i}/{N}')\n",
        "\n",
        "for i in range(len(Ip)):\n",
        "  n1_i = math.pi*w*Lp0mm_ys0[i]*10**(-9)*Ip[i]*math.sqrt(2)/(4*Vdc) # Note that Ip is rms value. #everything would be numpy\n",
        "  n2_i = (math.pi)**2*w*(Lp0mm_ys0[i]*10**(-9)*Ls0mm_ys0[i]*10**(-9))**0.5*Pout/(8*k0mm_ys0[i]*n1_i*Vdc*Vbat)\n",
        "  Is_i = 4*n2_i*Vbat/(math.pi*w*Ls0mm_ys0[i]*10**(-9))/math.sqrt(2)\n",
        "  VLp_i =( (((4*(Lp0mm_ys0[i])**0.5*Vbat*k0mm_ys0[i]*n2_i)/(math.pi*(Ls0mm_ys0[i])**0.5))**2 + (4*Vdc *n1_i/math.pi)**2)**0.5 )/(2**0.5) # Vrms\n",
        "  VLs_i =( (((4*(Ls0mm_ys0[i])**0.5*Vdc *k0mm_ys0[i]*n1_i)/(math.pi*(Lp0mm_ys0[i])**0.5))**2 + (4*Vbat*n2_i/math.pi)**2)**0.5 )/(2**0.5) # Vrms\n",
        "  Is.append(Is_i)\n",
        "  VLp.append(VLp_i)\n",
        "  VLs.append(VLs_i)\n",
        "  df_Is_temp = pd.DataFrame({'Is[A(rms)]':Is_i}, index=[i])\n",
        "  df_Is = pd.concat([df_Is, df_Is_temp])\n",
        "\n",
        "df_I = pd.concat([df_I_N, df_Is],axis=1)\n",
        "\n",
        "Pout_0mm=[]\n",
        "Pout_100mm=[]\n",
        "Pave=[]\n",
        "Pdiff=[]\n",
        "Pout = []\n",
        "\n",
        "Bx_0mm=[]\n",
        "By_0mm=[]\n",
        "Bz_0mm=[]\n",
        "Bx_100mm=[]\n",
        "By_100mm=[]\n",
        "Bz_100mm=[]\n",
        "Bstray=[]\n",
        "CoilLoss_100mm=[]\n",
        "Qcoil=400\n",
        "\n",
        "for i in range(len(Bx_p0mm0deg)):#=N  \n",
        "  Bx_100mm.append(((Bx_p100mm0deg[i]*Ip[i]*Np[i]+ Bx_s100mm0deg[i]*Is[i]*Ns[i] )**2 +(Bx_p100mm90deg[i]*Ip[i]*Np[i]+ Bx_s100mm90deg[i]*Is[i]*Ns[i] )**2)**0.5)\n",
        "  By_100mm.append(((By_p100mm0deg[i]*Ip[i]*Np[i]+ By_s100mm0deg[i]*Is[i]*Ns[i] )**2 +(By_p100mm90deg[i]*Ip[i]*Np[i]+ By_s100mm90deg[i]*Is[i]*Ns[i] )**2)**0.5)\n",
        "  Bz_100mm.append(((Bz_p100mm0deg[i]*Ip[i]*Np[i]+ Bz_s100mm0deg[i]*Is[i]*Ns[i] )**2 +(Bz_p100mm90deg[i]*Ip[i]*Np[i]+ Bz_s100mm90deg[i]*Is[i]*Ns[i] )**2)**0.5)\n",
        "  \n",
        "  Pout_0mm.append(w*k0mm_ys0[i]*(Lp0mm_ys0[i]*10**(-9)*Ls0mm_ys0[i]*10**(-9))**0.5*Ip[i]*Is[i] ) #[W]  \n",
        "  Pout_0mm_ys0_i = w*k0mm_ys0[i]*(Lp0mm_ys0[i]*10**(-9)*Ls0mm_ys0[i]*10**(-9))**0.5*Ip[i]*Is[i] #[W] \n",
        "  Pout_0mm_ys1_i = w*k0mm_ys1[i]*(Lp0mm_ys1[i]*10**(-9)*Ls0mm_ys1[i]*10**(-9))**0.5*Ip[i]*Is[i] #[W]  \n",
        "  Pout_0mm_ys2_i = w*k0mm_ys2[i]*(Lp0mm_ys2[i]*10**(-9)*Ls0mm_ys2[i]*10**(-9))**0.5*Ip[i]*Is[i] #[W]  \n",
        "  Pout_0mm_ys3_i = w*k0mm_ys3[i]*(Lp0mm_ys3[i]*10**(-9)*Ls0mm_ys3[i]*10**(-9))**0.5*Ip[i]*Is[i] #[W]  \n",
        "  Pout_0mm_ys4_i = w*k0mm_ys4[i]*(Lp0mm_ys4[i]*10**(-9)*Ls0mm_ys4[i]*10**(-9))**0.5*Ip[i]*Is[i] #[W]  \n",
        "  Pave_i = (Pout_0mm_ys0_i+2*Pout_0mm_ys1_i+2*Pout_0mm_ys2_i+2*Pout_0mm_ys3_i+2*abs(Pout_0mm_ys4_i))/8 # [W]/m\n",
        "  Pave.append(Pave_i)\n",
        "  if i % 1000 == 0:\n",
        "   print(f'Calculating Bstray... {i}/{N}')\n",
        "B_100mm = [(x**2 + y**2 + z**2)**0.5 for (x,y,z) in zip(Bx_100mm,By_100mm,Bz_100mm)] #[uT(rms)]\n",
        "\n",
        "df_pred_processed=df_pred\n",
        "df_pred_processed.insert(0, 'Is[A(rms)]', Is)\n",
        "df_pred_processed.insert(0, 'VLp[V(rms)]', VLp)\n",
        "df_pred_processed.insert(0, 'VLs[V(rms)]', VLs)\n",
        "df_pred_processed.insert(0, 'Bstray[uT(rms)]', B_100mm)\n",
        "df_pred_processed.insert(0, 'Pout_0mm[W]', Pout_0mm)\n",
        "df_pred_processed.insert(0, 'Pave[W/m]', Pave)"
      ],
      "metadata": {
        "id": "_G-lZo1kuGPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kdiff =[abs((x-y)/x)*100 for (x,y) in zip(k0mm_ys0,k100mm_ys0)]\n",
        "CoilLoss_0mm = [w*x1*10**(-9)*y1**2/Qcoil + w*x2*10**(-9)*y2**2/Qcoil for (x1,y1,x2,y2) in zip(Lp0mm_ys0,Ip,Ls0mm_ys0,Is)]\n",
        "\n",
        "lpy_df_pred = df_pred.loc[:,'lpy[mm]']\n",
        "lpx_df_pred = df_pred.loc[:,'lpx[mm]']\n",
        "wp_df_pred = df_pred.loc[:,'wp[mm]']\n",
        "a_df_pred = df_pred.loc[:,'a[mm]']\n",
        "p_df_pred = df_pred.loc[:,'p[mm]']\n",
        "ls_df_pred = df_pred.loc[:,'ls[mm]']\n",
        "ws_df_pred = df_pred.loc[:,'ws[mm]']\n",
        "b = 50 # mm\n",
        "# Core volume\n",
        "V_PriCore_temp = []\n",
        "V_PriCore = []\n",
        "V_SecCore_temp = []\n",
        "V_SecCore = []\n",
        "V_PriCore_ave_temp = []\n",
        "V_PriCore_ave = []\n",
        "num_temp = []\n",
        "num = []\n",
        "for i in range(len(lpy_df_pred)):\n",
        "  # Primary\n",
        "  lpx_i = lpx_df_pred.values[i]\n",
        "  lpy_i = lpy_df_pred.values[i]\n",
        "  wp_i = wp_df_pred.values[i]\n",
        "  a_i = a_df_pred.values[i]\n",
        "  p_i = p_df_pred.values[i]\n",
        "  V_PriCore_temp = (lpy_i+2*wp_i+2*a_i)*(lpx_i+2*wp_i+2*a_i)*5/(10**3) # cm3\n",
        "  V_PriCore.append(V_PriCore_temp) \n",
        "  V_PriCore_ave_temp = V_PriCore_temp/(lpy_i+2*wp_i+2*a_i+p_i)*10**3 # cm3/m\n",
        "  V_PriCore_ave.append(V_PriCore_ave_temp) \n",
        "  # Secondary\n",
        "  ls_i = ls_df_pred.values[i]  \n",
        "  ws_i = ws_df_pred.values[i]  \n",
        "  V_SecCore_temp = (ls_i+2*ws_i+2*b)**2*5/(10**3) # cm3\n",
        "  V_SecCore.append(V_SecCore_temp)   \n",
        "  # Number of inverter\n",
        "  num_temp = 1/(lpy_i+2*wp_i+2*a_i+p_i)*10**3 # 1/m\n",
        "  num.append(num_temp)\n",
        "  if i % 1000 ==0:\n",
        "   print(f'Calculating Vcore... {i}/{N}')\n",
        "\n",
        "# Windings volume\n",
        "V_PriWind_temp=[]\n",
        "V_PriWind = []\n",
        "V_SecWind_temp=[]\n",
        "V_SecWind = []\n",
        "V_PriWind_ave_temp = []\n",
        "V_PriWind_ave = []\n",
        "wout=[]\n",
        "for i in range(len(wp_df_pred)):\n",
        "  # Primary\n",
        "  lpx_i = lpx_df_pred.values[i]\n",
        "  lpy_i = lpy_df_pred.values[i]\n",
        "  wp_i = wp_df_pred.values[i]\n",
        "  a_i = a_df_pred.values[i]\n",
        "  p_i = p_df_pred.values[i]\n",
        "  V_PriWind_temp = (2*(lpx_i+wp_i)+2*(lpy_i+wp_i))*6.6*6.6/(10**3)*Np[i]   \n",
        "  V_PriWind.append(V_PriWind_temp)\n",
        "  V_PriWind_ave_temp = V_PriWind_temp/(lpy_i+2*wp_i+2*a_i+p_i)*10**3 # cm3/m\n",
        "  V_PriWind_ave.append(V_PriWind_ave_temp)\n",
        "  #Secondary\n",
        "  ls_i = ls_df_pred.values[i]\n",
        "  ws_i = ws_df_pred.values[i]\n",
        "  V_SecWind_temp = 4*(ls_i+ws_i)*6.6*6.6/(10**3)*Ns[i]   \n",
        "  V_SecWind.append(V_SecWind_temp)\n",
        "  if i % 1000 ==0:\n",
        "   print(f'Calculating Vwind... {i}/{N}')\n",
        "df_pred_processed.insert(0, 'kdiff[%]', kdiff)\n",
        "df_pred_processed.insert(0, 'V_PriCore_ave[cm3/m]', V_PriCore_ave)\n",
        "df_pred_processed.insert(0, 'V_PriWind_ave[cm3/m]', V_PriWind_ave)\n",
        "df_pred_processed.insert(0, 'V_SecCore[cm3]', V_SecCore)\n",
        "df_pred_processed.insert(0, 'V_SecWind[cm3]', V_SecWind)\n",
        "df_pred_processed.insert(0, 'Inverter[1/m]', num)\n",
        "df_pred_processed.insert(0, 'CoilLoss_0mm[W]', CoilLoss_0mm)\n",
        "\n",
        "df_pred_processed"
      ],
      "metadata": {
        "id": "uovQo6X-zPbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_1 = df_pred_processed\n",
        "fig_width = 8 #cm # Setting for Conference paper \n",
        "fig_height = 3 #cm\n",
        "font_size = 7 # pt\n",
        "fig_update = True\n",
        "marker_size = 5\n",
        "x_tick_pad = 2\n",
        "y_tick_pad = 2\n",
        "x_label_pad = 0.5\n",
        "y_label_pad = 1\n",
        "\n",
        "!pip install SciencePlots\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.reload_library()\n",
        "plt.style.use(['science','no-latex'])# ref: https://github.com/garrettj403/SciencePlots \n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'}) # Update the matplotlib configuration parameters:\n",
        "\n",
        "# distance between x and y axis and the numbers on the axes\n",
        "matplotlib.rcParams['xtick.major.pad'] = x_tick_pad\n",
        "matplotlib.rcParams['ytick.major.pad'] = y_tick_pad\n",
        "\n",
        "def cm2inch(value):\n",
        "    return value/2.54\n",
        "\n",
        "def upper_right(xlim, ylim):\n",
        "    x1 = np.arange(xlim,xlim*10,0.1)\n",
        "    y1 = ylim\n",
        "    y2 = ylim*10\n",
        "    plt.fill_between(x1,y1, y2 ,facecolor='r',alpha=0.3)#alpha is transperancy \n",
        "    plt.plot([xlim, xlim], [ylim, ylim*10], 'r--', lw=0.5)    # draw vertical line    \n",
        "    plt.plot([xlim,xlim*10], [ylim, ylim], 'r--', lw=0.5) # draw horizontal line # Ref: https://www.kite.com/python/docs/matplotlib.pyplot.fill_betwee\n",
        "\n",
        "def upper_left(xlim, ylim):\n",
        "    x1 = np.arange(0,xlim+0.1,0.1)\n",
        "    y1 = ylim\n",
        "    y2 = ylim*10\n",
        "    plt.fill_between(x1,y1, y2 ,facecolor='r',alpha=0.3)#alpha is transperancy\n",
        "    plt.plot([xlim, xlim], [ylim, ylim*10], 'r--', lw=0.5)    # draw vertical line     \n",
        "    plt.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5)  # draw horizontal line\n",
        "\n",
        "def lower_right(xlim, ylim):\n",
        "    x1 = np.arange(xlim,xlim*10,0.1)\n",
        "    y1 = 0\n",
        "    y2 = ylim\n",
        "    plt.fill_between(x1,y1, y2 ,facecolor='r',alpha=0.3)#alpha is transperancy\n",
        "    plt.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)    # draw vertical line     \n",
        "    plt.plot([xlim,xlim*10], [ylim, ylim], 'r--', lw=0.5)  # draw horizontal line\n",
        "\n",
        "def lower_left(xlim, ylim):\n",
        "    x1 = np.arange(0,xlim+0.1,0.1)\n",
        "    y1 = 0\n",
        "    y2 = ylim\n",
        "    plt.fill_between(x1,y1, y2 ,facecolor='r',alpha=0.3)#alpha is transperancy\n",
        "    plt.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)    # draw vertical line     \n",
        "    plt.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5)  # draw horizontal line "
      ],
      "metadata": {
        "id": "b036c8ZlbmQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Poster\n",
        "import numpy as np\n",
        "plt.style.use(['science','no-latex'])\n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "x = df_pred_1.loc[:,'Inverter[1/m]']\n",
        "y = df_pred_1.loc[:,'CoilLoss_0mm[W]']\n",
        "z = df_pred_1.loc[:,'Bstray[uT(rms)]']\n",
        "\n",
        "fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height)/1.2), dpi=400)\n",
        "xlim = 1.1 #Number of Inverter [1/m]\n",
        "ylim = 575 #Coil loss [W] \n",
        "lower_left(xlim,ylim)\n",
        "plt.scatter(x, y, c=z, s=marker_size, cmap ='viridis', vmin = 0, vmax=300,rasterized=True)\n",
        "plt.colorbar(label=r\"$B_{\\rm stray}~[\\rm \\mu T]$\")#Show colar bar at the right side \n",
        "plt.xlabel(r\"Number of inverter [1/m]\", labelpad = x_label_pad)              # not shown\n",
        "plt.ylabel(r'Coil loss [W]', labelpad = y_label_pad) # not shown\n",
        "plt.axis([0, 1.5, 0, 600])   \n",
        "plt.show()     \n",
        "df_pred_2=df_pred_1[(df_pred_1['Inverter[1/m]']<241)&(df_pred_1['CoilLoss_0mm[W]']<600) ]\n",
        "print(len(df_pred_2))"
      ],
      "metadata": {
        "id": "-3T58R0NzQyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.style.use(['science','no-latex'])\n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "x = df_pred_2.loc[:,'Bstray[uT(rms)]']\n",
        "y = df_pred_2.loc[:,'kdiff[%]']\n",
        "z = df_pred_2.loc[:,'V_PriCore_ave[cm3/m]']\n",
        "fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height/1.2)), dpi=400)\n",
        "xlim = 45 #Bstray[uT]\n",
        "ylim = 9 #kdiff[%] \n",
        "lower_left(xlim,ylim)\n",
        "plt.scatter(x, y, c=z, s=marker_size, cmap ='viridis', vmin = 0, vmax=6000,rasterized=True)\n",
        "plt.colorbar(label=r'$V_{\\rm PriCore}~[\\rm cm^3/m]$')#Show colar bar at the right side \n",
        "plt.xlabel(r\"$B_{\\rm stray}~[\\rm \\mu T]$\",labelpad = x_label_pad) # not shown\n",
        "plt.ylabel(r\"$k_{\\rm diff}~[\\%]$\",labelpad = y_label_pad)              # not shown\n",
        "plt.axis([0, 200, 0, 20])\n",
        "plt.show()     \n",
        "df_pred_3=df_pred_2[(df_pred_2['kdiff[%]']<15)&(df_pred_2['Bstray[uT(rms)]']<45) ]\n",
        "# print(df_pred_3)"
      ],
      "metadata": {
        "id": "bs8si1ptbnH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cbook import get_sample_data\n",
        "plt.style.use(['science','no-latex'])\n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "x = df_pred_3.loc[:,'V_SecCore[cm3]']\n",
        "y = (df_pred_3.loc[:,'Pave[W/m]'])/1000\n",
        "z = df_pred_3.loc[:,'V_SecWind[cm3]']\n",
        "print(x,y,z)\n",
        "fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height/1.2)), dpi=400)\n",
        "xlim = 1500 #_VSecCore[cm3]\n",
        "ylim = 30 #Pave[kW] \n",
        "upper_left(xlim,ylim)\n",
        "plt.scatter(x, y, c=z, s=marker_size, cmap ='viridis', vmin = 0, vmax=1000,rasterized=True)\n",
        "plt.colorbar(label=r'$V_{\\rm SecWind}~[\\rm cm^3]$')#Show colar bar at the right side \n",
        "plt.xlabel(r\"$V_{\\rm SecCore}~[\\rm cm^3]$\",labelpad = x_label_pad) # not shown\n",
        "plt.ylabel(r\"$P_{\\rm ave}~[\\rm kW/m]$\",labelpad = y_label_pad)              # not shown\n",
        "plt.axis([0, 6000, 0, 40]) \n",
        "plt.show()\n",
        "df_pred_4=df_pred_3[(df_pred_3['Pave[W/m]']>30000)&(df_pred_3['V_SecCore[cm3]']<1500)&(df_pred_3['V_SecWind[cm3]']<900) ]\n",
        "print(len(df_pred_4))"
      ],
      "metadata": {
        "id": "1bAN-nBtkIHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cbook import get_sample_data\n",
        "plt.style.use(['science','no-latex'])\n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "x = df_pred_4.loc[:,'VLp[V(rms)]']\n",
        "y = (df_pred_4.loc[:,'VLs[V(rms)]'])\n",
        "z = df_pred_4.loc[:,'Ip[A(rms)]']\n",
        "\n",
        "print(x,y,z)\n",
        "fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height/1.2)), dpi=400)\n",
        "xlim = 2000 # V(rms)\n",
        "ylim = 2000 # V(rms) \n",
        "lower_left(xlim,ylim)\n",
        "plt.scatter(x, y, c=z, s=marker_size, cmap ='viridis', vmin = 0, vmax=300,rasterized=True)\n",
        "plt.colorbar(label=r'$I_{\\rm P}~[\\rm A(rms)]$')#Show colar bar at the right side \n",
        "plt.xlabel(r\"$V_{\\rm Lp}~[\\rm V(rms)]$\",labelpad = x_label_pad) # not shown\n",
        "plt.ylabel(r\"$V_{\\rm Ls}~[\\rm V(rms)]$\",labelpad = y_label_pad)              # not shown\n",
        "plt.axis([0, 3000, 0, 3000]) \n",
        "plt.show()\n",
        "df_pred_5=df_pred_4[(df_pred_4['VLp[V(rms)]']>xlim)&(df_pred_4['VLs[V(rms)]']<ylim)]\n",
        "print(len(df_pred_5))"
      ],
      "metadata": {
        "id": "OkdyfOX6kKiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cbook import get_sample_data\n",
        "plt.style.use(['science','no-latex'])\n",
        "matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "x = df_pred_5.loc[:,'Ip[A(rms)]']\n",
        "y = (df_pred_5.loc[:,'Is[A(rms)]'])\n",
        "z = df_pred_5.loc[:,'VLp[V(rms)]']\n",
        "fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height/1.2)), dpi=400)\n",
        "xlim = 200 # A(rms)\n",
        "ylim = 200 # A(rms) \n",
        "lower_left(xlim,ylim)\n",
        "plt.scatter(x, y, c=z, s=marker_size, cmap ='viridis', vmin = 0, vmax=2000,rasterized=True)\n",
        "plt.colorbar(label=r'$V_{\\rm LP}~[\\rm A(rms)]$')#Show colar bar at the right side \n",
        "plt.xlabel(r\"$I_{\\rm P}~[\\rm A(rms)]$\",labelpad = x_label_pad) # not shown\n",
        "plt.ylabel(r\"$I_{\\rm S}~[\\rm A(rms)]$\",labelpad = y_label_pad)              # not shown\n",
        "plt.axis([0, 300, 0, 300]) \n",
        "plt.show()\n",
        "df_pred_6=df_pred_5[(df_pred_5['Ip[A(rms)]']>xlim)&(df_pred_5['Is[A(rms)]']<ylim)]\n",
        "print(len(df_pred_6))\n",
        "df_pred_6"
      ],
      "metadata": {
        "id": "WTegF6-kkNJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bQbgsb-2kVmh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "optimization_bstray_working (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}