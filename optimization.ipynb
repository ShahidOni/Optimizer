{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iZN2u5WKRFqR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torch import nn \n",
        "from torch import sigmoid\n",
        "from torch import atan\n",
        "from torch import tanh\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-TMPJtCKIM6"
      },
      "source": [
        "class Model(nn.Module): # Design your model using class\n",
        "  def __init__(self):    \n",
        "    super(Model, self).__init__() #In the constructor, we instantiate nn.Linear module.\n",
        "    self.linear1 = nn.Linear(12, 100, bias=True).cuda() # nn.Linear(<input size> ,<output size>)\n",
        "    self.linear2 = nn.Linear(100, 100, bias=True).cuda()\n",
        "    self.linear3 = nn.Linear(100, 42, bias=True).cuda()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = atan(self.linear1(x))\n",
        "    x = atan(self.linear2(x))\n",
        "    x = atan(self.linear2(x))\n",
        "    y_pred = self.linear3(x)\n",
        "    return y_pred\n",
        "model=Model() # our model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('saved_model_state.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9oqBtYCRR_c",
        "outputId": "9c6a3ba0-37e4-4729-e851-1e25a26df779"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cohI86mLj_Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_noise(a, b):\n",
        "  low,high = 0,1 #range of uniform distribution\n",
        "\n",
        "  x = torch.distributions.uniform.Uniform(low,high).sample([a,b]).cuda()\n",
        "  return x"
      ],
      "metadata": {
        "id": "dMoXnTFV8U1P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dense_layer = nn.Linear(int(input_length), 48).cuda()\n",
        "        self.dense_layer1 = nn.Linear(48, 96).cuda()\n",
        "        self.dense_layer2 = nn.Linear(96, int(input_length)).cuda()\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.activation(self.dense_layer(x))\n",
        "        x2 = self.activation(self.dense_layer1(x1))\n",
        "        x3 = self.activation(self.dense_layer2(x2))\n",
        "        return x3"
      ],
      "metadata": {
        "id": "z9cggAl1BGHo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "seed = 7777  \n",
        "random.seed(seed)  \n",
        "np.random.seed(seed)  \n",
        "torch.manual_seed(seed)\n",
        "generator = Generator(7)\n",
        "generator.requires_grad_= True"
      ],
      "metadata": {
        "id": "vuPxzX7KuP2l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaler (value, min , max):\n",
        "  scaled_value = value*(max - min) + min\n",
        "  return scaled_value"
      ],
      "metadata": {
        "id": "lmtwMfOB20K4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lpy_min = 50 #mm\n",
        "lpy_max = 2050 #mm\n",
        "lpx_min = 50 #mm\n",
        "lpx_max = 650 #mm\n",
        "wp_min = 25 # mm\n",
        "wp_max = 325 # mm\n",
        "a_min = 0 # mm\n",
        "a_max = 200 # mm\n",
        "p_min = 0 # mm\n",
        "p_max = 200 # mm\n",
        "ls_min = 50 # mm\n",
        "ls_max = 450 # mm\n",
        "ws_min = 25 # mm\n",
        "ws_max = 225 # mm\n",
        "# Ip_min = 50 # A rms\n",
        "# Ip_max = 200 # A rms\n",
        "# Np_min = 4 #turn\n",
        "# Np_max = 10 #turn\n",
        "# Ns_min = 4 #turn\n",
        "# Ns_max = 10 #turn"
      ],
      "metadata": {
        "id": "wsif7WTD8fO7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_array = [50,2050,50,650,25,325,0,200,0,200,50,450,25,225]"
      ],
      "metadata": {
        "id": "ORuDZR9NAwVw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_and_extract(arr):\n",
        "  for i in range(arr.shape[1]):\n",
        "    arr [:,i] = scaler(arr[:,i], scaler_array[2*i], scaler_array[2*i+1]).reshape(1, arr.shape[0])\n",
        "  y0_i = (arr[:,0]+arr[:,2])/2\n",
        "  y1_i = 3/2*arr[:,0] + 5/2*arr[:,2] + 2*arr[:,3]+arr[:,4] \n",
        "\n",
        "  ys_min = (y1_i).reshape(1, arr.shape[0])\n",
        "  ys_max = (y1_i+(y1_i-y0_i)/2).reshape(1,arr.shape[0])\n",
        "  ys = None\n",
        "  for i in range(arr.shape[0]):\n",
        "    if i == 0:\n",
        "      ys = torch.linspace(ys_min[0][i].item(),ys_max[0][i].item(), steps = 5)\n",
        "\n",
        "    else:\n",
        "      temp = torch.linspace(ys_min[0][i].item(),ys_max[0][i].item(), steps = 5)\n",
        "      ys = torch.vstack((ys, temp))\n",
        "\n",
        "  ys = ys.cuda()\n",
        "  ys0_i = ys[:,0].reshape(arr.shape[0],1)\n",
        "  ys1_i = ys[:,1].reshape(arr.shape[0],1)\n",
        "  ys2_i = ys[:,2].reshape(arr.shape[0],1)\n",
        "  ys3_i = ys[:,3].reshape(arr.shape[0],1)\n",
        "  ys4_i = ys[:,4].reshape(arr.shape[0],1)\n",
        "\n",
        "  arr = torch.hstack((arr, ys0_i, ys1_i, ys2_i, ys3_i, ys4_i))\n",
        "\n",
        "  return arr\n",
        "\n"
      ],
      "metadata": {
        "id": "xloGE25R8Jtm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING = 100\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(generator.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "3XEBoUqa3geO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(TRAINING):\n",
        "\n",
        "  noise = generate_noise(100,7)\n",
        "  GP = generator(noise)\n",
        "  scaled_array = scale_and_extract(GP)\n",
        "  MP = model(scaled_array)\n",
        "  kdiff = [abs((x-y)/x)*100 for (x,y) in zip(MP[:,0],MP[:,5])]\n",
        "  mean = torch.mean(torch.tensor(kdiff, requires_grad=True))\n",
        "  mean.backward()\n",
        "  print(mean)\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  #We want to maximize the kdiff\n",
        "\n",
        "\n",
        "  #KDIFF---\n",
        "  #k0mm_ys0 is column 15 and k100mm_ys0 is column 20, [0,41] in generated 42 parameters\n",
        "  #kdiff =[abs((x-y)/x)*100 for (x,y) in zip(k0mm_ys0,k100mm_ys0)] \n",
        "\n",
        "  #CALCULATE THE KDIFF AND OPTIMIZE IT\n",
        "  #BACKPROPAGATE \n",
        "  # kdiff.backward()\n",
        "  # optimizer.step()\n",
        "  # optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "BFEFwFVgApBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2cf360-7223-4195-a00d-1de396e1604b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(20.9466, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9470, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9454, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9481, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9502, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9450, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9523, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9496, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9514, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9479, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9450, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9469, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9478, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9467, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9435, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9508, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9464, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9469, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9495, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9459, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9416, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9479, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9487, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9462, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9453, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9474, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9486, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9470, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9473, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9480, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9508, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9482, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9472, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9515, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9468, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9472, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9456, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9473, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9453, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9438, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9409, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9470, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9487, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9477, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9483, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9496, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9478, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9494, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9507, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9486, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9493, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9476, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9447, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9503, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9514, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9496, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9461, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9495, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9439, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9453, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9498, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9465, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9483, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9467, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9437, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9457, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9524, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9510, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9472, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9468, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9445, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9483, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9473, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9502, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9492, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9465, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9470, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9442, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9429, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9414, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9470, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9490, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9487, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9527, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9491, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9530, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9424, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9475, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9484, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9475, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9444, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9529, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9491, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9513, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9433, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9458, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9465, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9453, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9483, grad_fn=<MeanBackward0>)\n",
            "tensor(20.9473, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    }
  ]
}