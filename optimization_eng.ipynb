{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yK8nRgzhEu0"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B70ehOEGIzN",
        "outputId": "40bcdf0c-6c8c-4127-b0d1-60a306f19953"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAUSSIAN = False\n",
        "pair_no = 8\n",
        "BASE_PATH = \"drive/MyDrive/\"\n",
        "#RESULT_PATH = \"optimization_result/\"+str(pair_no)+\"_for_all/\"\n",
        "RESULT_PATH = \"optimization_result/RandomForSix/\"\n",
        "FULL_PATH = BASE_PATH + RESULT_PATH\n"
      ],
      "metadata": {
        "id": "-gIf8XSPOQ1n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SciencePlots"
      ],
      "metadata": {
        "id": "k1sQxfp7svlj",
        "outputId": "7a398e32-d031-4c80-f0b4-fee9cb955bef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SciencePlots in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from SciencePlots) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SciencePlots) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SciencePlots) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SciencePlots) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SciencePlots) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->SciencePlots) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->SciencePlots) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->SciencePlots) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iZN2u5WKRFqR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pandas\n",
        "import numpy\n",
        "from scipy.optimize import curve_fit\n",
        "from torch.nn import ELU\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import imageio\n",
        "# seed = 7777\n",
        "# random.seed(seed) \n",
        "# torch.manual_seed(seed);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([.15])).sample(sample_shape = (100,10)).squeeze()\n",
        "# n  = torch.distributions.uniform.Uniform(-1, +1).sample((100,10))\n",
        "\n",
        "# print(m.shape,n.shape)\n",
        "\n",
        "a = '10'\n",
        "a.zfill(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFEJx_yyt5pr",
        "outputId": "71e2c5b2-8ebb-4eab-8a25-23b6bd49e1da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpfXJ0cchEu6"
      },
      "source": [
        "# Load Saved MP (Magnetic Parameter) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B-TMPJtCKIM6",
        "outputId": "9d353bac-152e-4865-87a2-2411af3e52f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c1d50eb1ba03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMpModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dwpt_v5/saved_model_state.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "# 12 input -> 42 output\n",
        "class MpModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MpModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(12, 100, bias=True)\n",
        "        self.linear2 = torch.nn.Linear(100, 100, bias=True)\n",
        "        self.linear3 = torch.nn.Linear(100, 42, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.atan(self.linear1(x))\n",
        "        x = torch.atan(self.linear2(x))\n",
        "        x = torch.atan(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "mp_model = MpModel().to(\"cuda\")\n",
        "mp_model.load_state_dict(torch.load(BASE_PATH + \"dwpt_v5/saved_model_state.pt\"))\n",
        "\n",
        "for param in mp_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6oZRKnZhEu8"
      },
      "source": [
        "# Create GP (Geometry Paramter) Generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elu = ELU(0)\n"
      ],
      "metadata": {
        "id": "ecz0WiczJXKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9cggAl1BGHo"
      },
      "outputs": [],
      "source": [
        "class GpModel(torch.nn.Module):\n",
        "    def __init__(self, input_length: int):\n",
        "        super(GpModel, self).__init__()\n",
        "\n",
        "        self.dense_layer1 = torch.nn.Linear(int(input_length), 128)\n",
        "        self.dense_layer2 = torch.nn.Linear(128, 256)\n",
        "        self.dense_layer3 = torch.nn.Linear(256, 512)\n",
        "        self.dense_layer4 = torch.nn.Linear(512, 256)\n",
        "        self.dense_layer5 = torch.nn.Linear(256, 128)\n",
        "        self.dense_layer6 = torch.nn.Linear(128, int(input_length))\n",
        "        \n",
        "        self.batch_norm1 = torch.nn.LazyBatchNorm1d()\n",
        "        self.batch_norm2 = torch.nn.LazyBatchNorm1d()\n",
        "        self.batch_norm3 = torch.nn.LazyBatchNorm1d()\n",
        "        self.batch_norm4 = torch.nn.LazyBatchNorm1d()\n",
        "        self.batch_norm5 = torch.nn.LazyBatchNorm1d()\n",
        "        self.activation = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm1(torch.atan(self.dense_layer1(x)))\n",
        "        x = self.batch_norm2(torch.atan(self.dense_layer2(x)))\n",
        "        x = self.batch_norm3(torch.atan(self.dense_layer3(x)))\n",
        "        x = self.batch_norm4(torch.atan(self.dense_layer4(x)))\n",
        "        x = self.batch_norm5(torch.atan(self.dense_layer5(x)))\n",
        "        x = self.activation(self.dense_layer6(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "gp_model = GpModel(10).to(\"cuda\")\n",
        "optimizer = torch.optim.Adam(gp_model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAyyPWgthEu_"
      },
      "source": [
        "# System Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bse1wsKN1NxY"
      },
      "outputs": [],
      "source": [
        "# x-direction of the primary winding (mm)\n",
        "lpx_min, lpx_max = (50.0, 650.0)\n",
        "\n",
        "# y-direction of the primary winding (mm)\n",
        "lpy_min, lpy_max = (50.0, 2050.0)\n",
        "\n",
        "# width of the primary winding (mm)\n",
        "wp_min, wp_max = (25.0, 325.0)\n",
        "\n",
        "# length of the edge of the primary core (mm)\n",
        "a_min, a_max = (0.0, 200.0)\n",
        "\n",
        "# pitch of the adjacent cores (mm)\n",
        "p_min, p_max = (0.0, 200.0)\n",
        "\n",
        "# length of the secondary winding (mm)\n",
        "ls_min, ls_max = (50.0, 450.0)\n",
        "\n",
        "# width of the secondary winding (mm)\n",
        "ws_min, ws_max = (25.0, 225.0)\n",
        "\n",
        "# input RMS current (A)\n",
        "ip_min, ip_max = (50.0, 200.0)\n",
        "\n",
        "# turn number of the primary side\n",
        "np_min, np_max = (4.0, 10.0)\n",
        "\n",
        "# turn number of the secondary side\n",
        "ns_min, ns_max = (4.0, 10.0)\n",
        "\n",
        "# switching frequency (kHz)\n",
        "f = 85 * (10 ** 3)\n",
        "\n",
        "# output power at the center (kW)\n",
        "p_out = 50 * (10 ** 3)\n",
        "\n",
        "# input DC voltage (V)\n",
        "v_dc = 400\n",
        "\n",
        "# output DC voltage (V)\n",
        "v_bat = 400\n",
        "\n",
        "# length of the edge of the secondary core\n",
        "b = 50\n",
        "\n",
        "# ???\n",
        "w = 2 * numpy.pi * f  # [rad/s]\n",
        "\n",
        "# ???\n",
        "q_coil = 400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqA9tUb9hEvC"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brlwMfzj1Nxh"
      },
      "outputs": [],
      "source": [
        "# Creates a tensor of shape [num, *start.shape] whose values are evenly spaced from start to end, inclusive.\n",
        "# Replicates but the multi-dimensional bahaviour of numpy.linspace in PyTorch.\n",
        "\n",
        "@torch.jit.script\n",
        "def linspace(start: torch.Tensor, stop: torch.Tensor, num: int):\n",
        "    # create a tensor of 'num' steps from 0 to 1\n",
        "    steps = torch.arange(num, dtype=torch.float32, device=start.device) / (num - 1)\n",
        "\n",
        "    # reshape the 'steps' tensor to [-1, *([1]*start.ndim)] to allow for broadcastings\n",
        "    # - using 'steps.reshape([-1, *([1]*start.ndim)])' would be nice here but torchscript\n",
        "    #   \"cannot statically infer the expected size of a list in this contex\", hence the code below\n",
        "    for i in range(start.ndim):\n",
        "        steps = steps.unsqueeze(-1)\n",
        "\n",
        "    # the output starts at 'start' and increments until 'stop' in each dimension\n",
        "    out = start[None] + steps * (stop - start)[None]\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMoXnTFV8U1P"
      },
      "outputs": [],
      "source": [
        "# Generate a pytorch tensor full of random floats in the range [-1, +1] with the given shape\n",
        "def generate_noise(shape, gaussian=False):\n",
        "    if gaussian:\n",
        "      return torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([.15])).sample(sample_shape = shape).squeeze().cuda()\n",
        "    return torch.distributions.uniform.Uniform(-1, +1).sample(shape).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xloGE25R8Jtm"
      },
      "outputs": [],
      "source": [
        "def stack_parameters(*params):\n",
        "    return torch.stack(params).transpose(0, 1)\n",
        "\n",
        "\n",
        "# Scale an array to be between our specified [min, max] contraints\n",
        "def scale(arr):\n",
        "    scaler_min = torch.tensor(\n",
        "        [a_min, lpx_min, lpy_min, ls_min, p_min, wp_min, ws_min, ip_min, np_min, ns_min],\n",
        "        device=\"cuda\",\n",
        "    )\n",
        "    scaler_max = torch.tensor(\n",
        "        [a_max, lpx_max, lpy_max, ls_max, p_max, wp_max, ws_max, ip_max, np_max, ns_max],\n",
        "        device=\"cuda\",\n",
        "    )\n",
        "    return arr * (scaler_max - scaler_min) + scaler_min\n",
        "\n",
        "\n",
        "def extract(arr):\n",
        "    a, lpx, lpy, ls, p, wp, ws, ip, np, ns = [\n",
        "        numpy.squeeze(x) for x in numpy.hsplit(arr, 10)\n",
        "    ]\n",
        "\n",
        "    ys_min = (\n",
        "        5 * wp +\n",
        "        4 * a +\n",
        "        3 * lpy +\n",
        "        2 * p\n",
        "    )\n",
        "\n",
        "    ys_max = (lpy + wp)\n",
        "    ys_max = ys_min + (ys_min - ys_max) / 2\n",
        "\n",
        "    ys_min /= 2\n",
        "    ys_max /= 2\n",
        "\n",
        "    ys = linspace(ys_min, ys_max, num=5)\n",
        "\n",
        "    np = torch.round(np)\n",
        "    ns = torch.round(ns)\n",
        "\n",
        "    # take all 15 tensors of shape (X) and convert to (15, X)\n",
        "    return a, lpx, lpy, ls, p, wp, ws, ip, np, ns, ys\n",
        "\n",
        "\n",
        "def scale_and_extract(arr):\n",
        "    scaled_array = scale(arr)\n",
        "    return extract(scaled_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44TlTSnclCKs"
      },
      "outputs": [],
      "source": [
        "# Enclose in a function so we don't leak variables\n",
        "def test_models():\n",
        "    noise = generate_noise(shape=(256, 10))\n",
        "    gp = gp_model(noise)\n",
        "    a, lpx, lpy, ls, p, wp, ws, ip, np, ns, ys = scale_and_extract(gp)\n",
        "\n",
        "    gp_parameters = stack_parameters(a, lpx, lpy, ls, p, wp, ws, *ys)\n",
        "    extra_parameters = stack_parameters(ip, np, ns)\n",
        "\n",
        "    mp = mp_model(gp_parameters)\n",
        "\n",
        "    print(f\"\"\"\n",
        "    GP Parameters Shape:    {gp_parameters.shape}\n",
        "    Extra Parameters Shape: {extra_parameters.shape}\n",
        "    MP Model Output Shape:  {mp.shape}\n",
        "    \"\"\")\n",
        "test_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEb7J5bOFEEr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Method to take two equally-sized lists and return just the elements which lie \n",
        "on the Pareto frontier, sorted into order.\n",
        "Default behaviour is to find the maximum for both X and Y, but the option is\n",
        "available to specify maxX = False or maxY = False to find the minimum for either\n",
        "or both of the parameters.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def pareto_frontier(x, y, max_x=False):\n",
        "    if max_x:\n",
        "        return _pareto_frontier(y, x)\n",
        "    else:\n",
        "        return _pareto_frontier(x, y)\n",
        "\n",
        "\n",
        "def _pareto_frontier(x, y):\n",
        "    # Combine inputs and sort them with smallest X values coming first\n",
        "    sorted_xy = sorted(zip(x, y))\n",
        "    p_front_x = torch.zeros(len(x), device=\"cuda\")\n",
        "    p_front_y = torch.zeros(len(y), device=\"cuda\")\n",
        "    \n",
        "    # Loop through the sorted list\n",
        "    #   Look for lower values of Y…\n",
        "    #   and add them to the Pareto frontier\n",
        "    min_y = sorted_xy[0][1]\n",
        "    for index in range(len(sorted_xy)):\n",
        "        x, y = sorted_xy[index]\n",
        "        if y < min_y:\n",
        "            min_y = y\n",
        "            p_front_x[index] = x\n",
        "            p_front_y[index] = y\n",
        "            \n",
        "    p_front_x = p_front_x[p_front_x.nonzero()]\n",
        "    p_front_y = p_front_y[p_front_y.nonzero()]\n",
        "\n",
        "    return p_front_x, p_front_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV3xWUXBhEvJ"
      },
      "outputs": [],
      "source": [
        "def y_util(x, a, b, c):\n",
        "    return (1 / (a * (x**b)))**c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_from_origin(*args):\n",
        "  distance = 0\n",
        "  for objective in args:\n",
        "    distance += torch.pow(objective,2)\n",
        "  \n",
        "  return distance"
      ],
      "metadata": {
        "id": "YS_UYwm9l9UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQzi6XchEvJ"
      },
      "source": [
        "# Load DWPT data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkTrlAJMH5UO"
      },
      "outputs": [],
      "source": [
        "def load_dwpt():\n",
        "    folder_name = BASE_PATH + \"dwpt_v5\"\n",
        "    file_names = [\n",
        "        \"DWPT_v5_N10\",\n",
        "        \"DWPT_v5_N100\",\n",
        "        \"DWPT_v5_N200\",\n",
        "        \"DWPT_v5_N300\",\n",
        "        \"DWPT_v5_N400\",\n",
        "    ]\n",
        "\n",
        "    df = pandas.DataFrame()\n",
        "\n",
        "    for file_name in file_names:\n",
        "        new_df = pandas.read_csv(f\"{folder_name}/{file_name}_after.csv\", index_col=0)\n",
        "        df = pandas.concat([df, new_df])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_dwpt()\n",
        "df_gp = df.loc[:, :\"ys4[mm]\"]\n",
        "df_mp = df.loc[:, \"k0mm_ys0\":]\n",
        "\n",
        "print(df_gp.shape)\n",
        "print(df_mp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = []\n",
        "file1 = open(BASE_PATH + 'dwpt_v5/pairs.txt', 'r')\n",
        "lines = file1.readlines()\n",
        "for line in lines:\n",
        "  pairs.append([int(i) for i in line.strip().split(',')])\n",
        "pair = pairs[pair_no]\n",
        "print(pair)"
      ],
      "metadata": {
        "id": "o02c1gNSHNOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "magic_number = 10 ** (-9)"
      ],
      "metadata": {
        "id": "A5dB6EUcWYy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPDZ4IvUhEvL"
      },
      "source": [
        "# Define Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooTuqXyahEvM"
      },
      "outputs": [],
      "source": [
        "def kdiff_loss(k_parameters):\n",
        "    (\n",
        "        k_0_0, k_0_1, k_0_2, k_0_3, k_0_4, k_1_0,\n",
        "    ) = k_parameters\n",
        "\n",
        "    kdiff = abs(k_0_0 - k_1_0)\n",
        "    kdiff = kdiff / torch.max(abs(k_0_0), abs(k_1_0))\n",
        "\n",
        "    return kdiff\n",
        "\n",
        "\n",
        "def calculate_Is(l_parameters, k_parameters):\n",
        "  (\n",
        "      k_0_0, k_0_1, k_0_2, k_0_3, k_0_4, k_1_0,\n",
        "  ) = k_parameters\n",
        "  (\n",
        "      lp_0_0, lp_0_1, lp_0_2, lp_0_3, lp_0_4,\n",
        "      ls_0_0, ls_0_1, ls_0_2, ls_0_3, ls_0_4,\n",
        "      lp_1_0, ls_1_0,\n",
        "  ) = l_parameters\n",
        "\n",
        "  a6 = lp_0_0 * np ** 2\n",
        "  a11 = ls_0_0 * ns ** 2 \n",
        "  # Paper formula\n",
        "  n1 = (torch.pi * w * a6 * ip) / (2 * numpy.sqrt(2) * v_dc)\n",
        "  t1 = (torch.pi ** 2 * w * p_out * torch.sqrt(a6 * a11))\n",
        "  t2 = 8 * k_0_0 * n1 * v_dc * v_bat\n",
        "  n2 = t1 / t2\n",
        "  Is = (4 * v_bat * n2) / (torch.pi * w * a11)\n",
        "\n",
        "  return Is\n",
        "  \n",
        "def bstray_loss(k_parameters, l_parameters, b_parameters, extra_parameters):\n",
        "    # Unpack parameters\n",
        "    (\n",
        "        k_0_0, k_0_1, k_0_2, k_0_3, k_0_4, k_1_0,\n",
        "    ) = k_parameters\n",
        "    (\n",
        "        lp_0_0, lp_0_1, lp_0_2, lp_0_3, lp_0_4,\n",
        "        ls_0_0, ls_0_1, ls_0_2, ls_0_3, ls_0_4,\n",
        "        lp_1_0, ls_1_0,\n",
        "    ) = l_parameters\n",
        "    (\n",
        "        bx_p_0_00, by_p_0_00, bz_p_0_00,\n",
        "        bx_p_0_90, by_p_0_90, bz_p_0_90,\n",
        "        bx_s_0_00, by_s_0_00, bz_s_0_00,\n",
        "        bx_s_0_90, by_s_0_90, bz_s_0_90,\n",
        "\n",
        "        bx_p_1_00, by_p_1_00, bz_p_1_00,\n",
        "        bx_p_1_90, by_p_1_90, bz_p_1_90,\n",
        "        bx_s_1_00, by_s_1_00, bz_s_1_00,\n",
        "        bx_s_1_90, by_s_1_90, bz_s_1_90,\n",
        "    ) = b_parameters\n",
        "    (\n",
        "        ip, np, ns\n",
        "    ) = extra_parameters\n",
        "\n",
        "    Is = calculate_Is(l_parameters,k_parameters)\n",
        "\n",
        "    bx_100 = (\n",
        "        (bx_p_1_00 * ip * np + bx_s_1_00 * Is * ns) ** 2 +\n",
        "        (bx_p_1_90 * ip * np + bx_s_1_90 * Is * ns) ** 2\n",
        "    ) ** 0.5\n",
        "    by_100 = (\n",
        "        (by_p_1_00 * ip * np + by_s_1_00 * Is * ns) ** 2 +\n",
        "        (by_p_1_90 * ip * np + by_s_1_90 * Is * ns) ** 2\n",
        "    ) ** 0.5\n",
        "    bz_100 = (\n",
        "        (bz_p_1_00 * ip * np + bz_s_1_00 * Is * ns) ** 2 +\n",
        "        (bz_p_1_90 * ip * np + bz_s_1_90 * Is * ns) ** 2\n",
        "    ) ** 0.5\n",
        "    b_100 = (bx_100**2 + by_100**2 + bz_100**2) ** 0.5\n",
        "\n",
        "    bstray = b_100\n",
        "\n",
        "    return bstray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "f = 85*10**3 #[Hz]\n",
        "w =2*math.pi*f #[rad/s]\n",
        "Pout= 50000 #W\n",
        "Vdc = 400 #800 # V\n",
        "Vbat = 400 #V\n",
        "QCoil = 400\n",
        "b = 50"
      ],
      "metadata": {
        "id": "4iNocy5Z3sO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coil_loss_and_power_average(k_parameters, l_parameters, b_parameters, extra_parameters):\n",
        "  (\n",
        "      k_0_0, k_0_1, k_0_2, k_0_3, k_0_4, k_1_0,\n",
        "  ) = k_parameters\n",
        "  (\n",
        "      lp_0_0, lp_0_1, lp_0_2, lp_0_3, lp_0_4,\n",
        "      ls_0_0, ls_0_1, ls_0_2, ls_0_3, ls_0_4,\n",
        "      lp_1_0, ls_1_0,\n",
        "  ) = l_parameters\n",
        "  (\n",
        "      bx_p_0_00, by_p_0_00, bz_p_0_00,\n",
        "      bx_p_0_90, by_p_0_90, bz_p_0_90,\n",
        "      bx_s_0_00, by_s_0_00, bz_s_0_00,\n",
        "      bx_s_0_90, by_s_0_90, bz_s_0_90,\n",
        "\n",
        "      bx_p_1_00, by_p_1_00, bz_p_1_00,\n",
        "      bx_p_1_90, by_p_1_90, bz_p_1_90,\n",
        "      bx_s_1_00, by_s_1_00, bz_s_1_00,\n",
        "      bx_s_1_90, by_s_1_90, bz_s_1_90,\n",
        "  ) = b_parameters\n",
        "  (\n",
        "      ip, np, ns\n",
        "  ) = extra_parameters\n",
        "\n",
        "\n",
        "  a6 = lp_0_0 * np**2  # LP0MM_YSO\n",
        "  a7 = lp_0_1 * np**2  # LP0MM_YS1\n",
        "  a8 = lp_0_2 * np**2  # LP0MM_YS2\n",
        "  a9 = lp_0_3 * np**2  # LP0MM_YS3\n",
        "  a10 = lp_0_4* np**2 # LP0MM_YS4\n",
        "\n",
        "  a11 = ls_0_0 * ns**2 # LS0MM_YSO\n",
        "  a12 = ls_0_1 * ns**2 # LS0MM_YS1\n",
        "  a13 = ls_0_2 * ns**2 # LS0MM_YS2\n",
        "  a14 = ls_0_3 * ns**2 # LS0MM_YS3\n",
        "  a15 = ls_0_4 * ns**2 # LS0MM_YS4\n",
        "\n",
        "  Is = calculate_Is(l_parameters,k_parameters)\n",
        "  \n",
        "  loss = (w*a6*ip**2/QCoil + w*a11*Is**2/QCoil) * 10 ** -9\n",
        "\n",
        "  p0 = w*k_0_0*(a6*a11)**0.5*ip*Is\n",
        "  p1 = w*k_0_1*(a7*a12)**0.5*ip*Is\n",
        "  p2 = w*k_0_2*(a8*a13)**0.5*ip*Is\n",
        "  p3 = w*k_0_3*(a9*a14)**0.5*ip*Is\n",
        "  p4 = 2*w*k_0_4*(a10*a15)**0.5*ip*Is\n",
        "  pave = (p0+(2*p1)+(2*p2)+(2*p3)+p4)/8 \n",
        "\n",
        "  return loss,pave\n",
        "\n"
      ],
      "metadata": {
        "id": "_xFmgOR23TBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_inverters(gp_parameters):\n",
        "  (\n",
        "        a, lpx, lpy, ls, p, wp, ws, *ys\n",
        "  ) = gp_parameters.clone().transpose(0,1)\n",
        "  number_of_inverters = 1/(lpy+2*wp+2*a+p)*10**3\n",
        "  return number_of_inverters"
      ],
      "metadata": {
        "id": "_9TE0J9eYPrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def core_losses(extra_parameters, gp_parameters):\n",
        "    (\n",
        "        ip, np, ns\n",
        "    ) = extra_parameters\n",
        "\n",
        "    (\n",
        "        a, lpx, lpy, ls, p, wp, ws, *ys\n",
        "    ) = gp_parameters.transpose(0,1)\n",
        "    \n",
        "    V_PriCore = ((lpy +2*wp+2*a)*(lpx+2*wp+2*a)*5)/(10**3) # cm3\n",
        "    V_SecCore = (((ls+2*ws+2*b)**2)*5)/(10**3)\n",
        "    V_PriWind = (2*(lpx+wp)+2*(lpy+wp))*6.6*6.6/(10**3)*np\n",
        "    V_SecWind = 4*(ls+ws)*6.6*6.6/(10**3)*ns\n",
        "\n",
        "    return V_PriCore, V_SecCore, V_PriWind, V_SecWind"
      ],
      "metadata": {
        "id": "rg6ZLG4NO5zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function_relu(params, max,min=False):\n",
        "\n",
        "  relu = torch.nn.ReLU()\n",
        "  return relu(params - max/torch.max(params))\n"
      ],
      "metadata": {
        "id": "kxb1xWC4zpP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function_power_avg(params,max_val = 30000):\n",
        "  max_ = torch.max(params)\n",
        "  if  max_ < max_val:\n",
        "    return 0\n",
        "  else:\n",
        "    return max_val - max_"
      ],
      "metadata": {
        "id": "elUyFh4bWl2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle"
      ],
      "metadata": {
        "id": "HggqfQlUtZNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqYxKG8ThEvN"
      },
      "outputs": [],
      "source": [
        "noise = generate_noise(shape=(25_000, 10))\n",
        "gp = gp_model(noise)\n",
        "\n",
        "# Unpack and filter GP parameters\n",
        "a, lpx, lpy, ls, p, wp, ws, ip, np, ns, ys = scale_and_extract(gp)\n",
        "gp_parameters = stack_parameters(a, lpx, lpy, ls, p, wp, ws, *ys)\n",
        "extra_parameters = stack_parameters(ip, np, ns).transpose(0, 1)\n",
        "\n",
        "\n",
        "V_PriCore, V_SecCore, V_PriWind,V_SecWind = core_losses(extra_parameters, gp_parameters)\n",
        "\n",
        "min_x = torch.min(gp_parameters)\n",
        "max_x = torch.max(gp_parameters)\n",
        "gp_parameters = (gp_parameters - min_x) / (max_x - min_x)\n",
        "# Push GP parameters through MP model\n",
        "mp_parameters = mp_model(gp_parameters)\n",
        "\n",
        "\n",
        "# Scale MP parameters\n",
        "y = torch.Tensor(df_mp.values).transpose(0, 1).to(\"cuda\")\n",
        "min_y = torch.min(y, 1).values\n",
        "max_y = torch.max(y, 1).values\n",
        "mp_parameters = mp_parameters * (max_y - min_y) + min_y\n",
        "\n",
        "k_parameters = mp_parameters.transpose(0, 1)[0:6]\n",
        "l_parameters = mp_parameters.transpose(0, 1)[6:18]\n",
        "b_parameters = mp_parameters.transpose(0, 1)[18:]\n",
        "\n",
        "kdiff = kdiff_loss(k_parameters)\n",
        "bstray = bstray_loss(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "coilloss,pave = coil_loss_and_power_average(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "print(\"pave\",pave,coilloss, bstray)\n",
        "print(loss_function_power_avg(pave))\n",
        "plt.vlines(x=40,ymin = 0, ymax=.15,color='red',linestyle='dashed')\n",
        "plt.hlines(y=.15,xmin = 0, xmax=40,color='red',linestyle='dashed')\n",
        "plt.vlines(x=0,ymin = 0, ymax=.15,color='red',linestyle='dashed')\n",
        "plt.hlines(y=0,xmin = 0, xmax=40,color='red',linestyle='dashed')\n",
        "#display plot\n",
        "plt.scatter(bstray.detach().cpu(), 100 * kdiff.detach().cpu())\n",
        "plt.title(\"Random Network: Bstray vs Kdiff\")\n",
        "plt.xlabel(\"BStray\")\n",
        "plt.ylabel(\"Coupling %\")\n",
        "plt.show()\n",
        "\n",
        "plt.vlines(x=2000,ymin = 0, ymax=.15,color='red',linestyle='dashed')\n",
        "plt.hlines(y=.15,xmin = 0, xmax=2000,color='red',linestyle='dashed')\n",
        "plt.vlines(x=0,ymin = 0, ymax=.15,color='red',linestyle='dashed')\n",
        "plt.hlines(y=0,xmin = 0, xmax=2000,color='red',linestyle='dashed')\n",
        "plt.scatter(coilloss.detach().cpu(), 100 * kdiff.detach().cpu())\n",
        "plt.title(\"Random Network: Coilloss vs Kdiff\")\n",
        "plt.xlabel(\"Coilloss\")\n",
        "plt.ylabel(\"Coupling %\")\n",
        "plt.show()\n",
        "\n",
        "number_of_inverters(gp_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting"
      ],
      "metadata": {
        "id": "sCRWTuRQQJl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_width = 8 #cm # Setting for Conference paper \n",
        "fig_height = 3 #cm\n",
        "font_size = 7 # pt\n",
        "fig_update = True\n",
        "marker_size = 5\n",
        "x_tick_pad = 2\n",
        "y_tick_pad = 2\n",
        "x_label_pad = 0.5\n",
        "y_label_pad = 1"
      ],
      "metadata": {
        "id": "Bi975HvSQ8PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import seaborn as sns\n",
        "plt.style.use(['science','no-latex'])\n",
        "def plot_(**kwargs):\n",
        "  import numpy as np\n",
        "  plt.close('all')\n",
        "  kdiff = kwargs[\"kdiff\"] * 100\n",
        "  pave = kwargs[\"pave\"] /1000\n",
        "  coilloss = kwargs[\"coilloss\"]\n",
        "  bstray = kwargs[\"bstray\"]\n",
        "  vpricore = kwargs[\"vpricore\"]\n",
        "  vsecwind = kwargs[\"vsecwind\"]\n",
        "  n_inv = kwargs[\"n_inv\"]\n",
        "  vseccore = kwargs[\"vseccore\"]\n",
        "  epoch = kwargs[\"epoch\"]\n",
        "\n",
        "  marker_size = 1\n",
        "  \n",
        "\n",
        "  font = {'family' : 'normal',\n",
        "          'weight' : 'bold',\n",
        "          'size'   : 12}\n",
        "\n",
        "  matplotlib.rc('font', **font)\n",
        "  \n",
        "  #plt.style.use(['science','no-latex'])\n",
        "\n",
        "  fig, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4)\n",
        "\n",
        "  #fig.subplots_adjust(hspace=10)\n",
        "\n",
        "  fig.set_size_inches(16,4)\n",
        "  #ax1.set_aspect('equal')\n",
        "  #fig.tight_layout(pad=6)\n",
        "  fig.tight_layout(pad = 2)\n",
        "\n",
        "  xlim = 1 #Number of Inverter [1/m]\n",
        "  ylim = 2000 #Coil loss [W] \n",
        "  ax1.set_xlabel(r\"$Number\\ of\\ inverter\\ [1/m]$\", labelpad = x_label_pad)              # not shown\n",
        "  ax1.set_ylabel(r'$Coil loss [W]$', labelpad = y_label_pad) # not shown\n",
        "  x1 = np.arange(0, xlim + 0.1,0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "  plt_ax1 = ax1.scatter(n_inv, coilloss, s=marker_size, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax1 , ax = ax1, label=r\"$B_{\\rm stray}~[\\rm \\mu T]$\")\n",
        "  ax1.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax1.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax1.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax1.axis([0,2, 0,5000])\n",
        "  ax1.tick_params(axis='x', pad=15)\n",
        "  # ax1.set_aspect('equal')\n",
        "\n",
        "\n",
        "\n",
        "  xlim = 100\n",
        "  ylim = 40\n",
        "  ax2.set_xlabel(r\"$B_{\\rm stray}~[\\rm \\mu T]$\", labelpad = x_label_pad)              # not shown\n",
        "  ax2.set_ylabel(r'$Coupling [\\%]$', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "\n",
        "  plt_ax2 = ax2.scatter(bstray, kdiff,s=marker_size,rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax2 , ax = ax2, label=r\"$V_{PriCore}$\")\n",
        "  ax2.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax2.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax2.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax2.axis([0, 200, 0, 60])\n",
        "  ax2.tick_params(axis='x', pad=15)\n",
        "\n",
        "  # ax2.set_aspect('equal')\n",
        "\n",
        "  xlim = 3500\n",
        "  ylim = 30\n",
        "\n",
        "  ax3.set_xlabel(r\"$V_{SecCore}$\", labelpad = x_label_pad)              # not shown\n",
        "  ax3.set_ylabel(r'$P_{ave} [KW/M]$', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = ylim\n",
        "  y2 = ylim*10\n",
        "\n",
        "  ax3.scatter(vseccore, pave,s=marker_size, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax3 , ax = ax3, label=r\"$V_{SecWind}$\")\n",
        "  ax3.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax3.plot([xlim, xlim], [ylim, ylim*10], 'r--', lw=0.5)  \n",
        "  ax3.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax3.axis([0, 5000, 0, 50])\n",
        "  ax3.tick_params(axis='x', pad=15)\n",
        "  # ax3.set_aspect('equal')\n",
        "\n",
        "\n",
        "  xlim = 750\n",
        "  ylim = 6000\n",
        "\n",
        "  ax4.set_xlabel(r\"$V_{SecWind}$\", labelpad = x_label_pad)              # not shown\n",
        "  ax4.set_ylabel(r'$V_{PriCore} $', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "\n",
        "  ax4.scatter(vsecwind, vpricore, s=marker_size, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax3 , ax = ax3, label=r\"$V_{SecWind}$\")\n",
        "  ax4.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax4.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax4.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax4.axis([0, 2000, 0, 8000])\n",
        "  ax4.tick_params(axis='x', pad=15)\n",
        "\n",
        "  plt.suptitle(\"Epoch \"+str(epoch).zfill(5), y = 1.05, c='r')\n",
        "  plt.savefig(FULL_PATH + str(epoch).zfill(5)+\".png\")\n",
        "\n",
        "  plt.clf()\n",
        "  \n"
      ],
      "metadata": {
        "id": "4dUgIs81QJBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accepted_solution(**kwargs):\n",
        "\n",
        "  kdiff = kwargs[\"kdiff\"] * 100\n",
        "  pave = kwargs[\"pave\"]/1000\n",
        "  coilloss = kwargs[\"coilloss\"]\n",
        "  bstray = kwargs[\"bstray\"]\n",
        "  vpricore = kwargs[\"vpricore\"]\n",
        "  vsecwind = kwargs[\"vsecwind\"]\n",
        "  n_inv = kwargs[\"n_inv\"]\n",
        "  vseccore = kwargs[\"vseccore\"]\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(kdiff)):\n",
        "    if n_inv[i] < 1 and coilloss[i] < 2000 and bstray[i] < 50 and \\\n",
        "    kdiff[i] < 50 and vseccore[i] < 1500 and pave[i] > 30:# and vsecwind[i] < 750 and vpricore[i] < 6000:\n",
        "      count += 1\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "3eAZGfDTndEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_solution_plot(**kwargs):\n",
        "  kdiff = kwargs[\"kdiff\"] * 100\n",
        "  pave = kwargs[\"pave\"] /1000\n",
        "  coilloss = kwargs[\"coilloss\"]\n",
        "  bstray = kwargs[\"bstray\"]\n",
        "  vpricore = kwargs[\"vpricore\"]\n",
        "  vsecwind = kwargs[\"vsecwind\"]\n",
        "  n_inv = kwargs[\"n_inv\"]\n",
        "  vseccore = kwargs[\"vseccore\"]\n",
        "\n",
        "  accepted_n_inv_ = [] \n",
        "  accepted_coilloss = [] \n",
        "  accepted_bstray = []\n",
        "  accepted_kdiff = []\n",
        "  accepted_v_sec_core = []\n",
        "  accpeted_pave = []\n",
        "  accepted_v_sec_wind = []\n",
        "  accpeted_v_pri_core = []\n",
        "\n",
        "  for i in range(len(kdiff)):\n",
        "    if n_inv[i] < 1 and coilloss[i] < 2000 and bstray[i] < 50 and \\\n",
        "    kdiff[i] < 40 and vseccore[i] < 1500 and pave[i] > 30:# and vsecwind[i] < 750 and vpricore[i] < 6000:\n",
        "      accepted_n_inv_.append(n_inv[i])\n",
        "      accepted_coilloss.append(coilloss[i])\n",
        "      accepted_bstray.append(bstray[i])\n",
        "      accepted_kdiff.append(kdiff[i])\n",
        "      accepted_v_sec_core.append(vseccore[i])\n",
        "      accpeted_pave.append(pave[i])\n",
        "      accepted_v_sec_wind.append(vsecwind[i])\n",
        "      accpeted_v_pri_core.append(vpricore[i])\n",
        "\n",
        "\n",
        "  import matplotlib\n",
        "  import seaborn as sns\n",
        "  import numpy as np\n",
        "\n",
        "  plt.subplots_adjust(left=.1,\n",
        "                      bottom=0.1,\n",
        "                      right=0.9,\n",
        "                      top=2,\n",
        "                      wspace=2,\n",
        "                      hspace=0.4)\n",
        "\n",
        "  font = {'family' : 'normal',\n",
        "          'weight' : 'bold',\n",
        "          'size'   : 15}\n",
        "\n",
        "  matplotlib.rc('font', **font)\n",
        "  color_list = sns.color_palette(\"Paired\", n_colors=len(accpeted_v_pri_core))\n",
        "\n",
        "  plt.style.use(['science','no-latex'])\n",
        "  #matplotlib.rcParams.update({'font.size': font_size, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
        "\n",
        "\n",
        "  #fig1=plt.figure(figsize=(cm2inch(fig_width/2),cm2inch(fig_height)/1.2), dpi=400)\n",
        "\n",
        "  marker_size = 50\n",
        "\n",
        "  #plt.style.use(['science','no-latex'])\n",
        "\n",
        "  fig, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4)\n",
        "\n",
        "  #fig.subplots_adjust(hspace=10)\n",
        "\n",
        "  fig.set_size_inches(16,4)\n",
        "  #ax1.set_aspect('equal')\n",
        "  #fig.tight_layout(pad=6)\n",
        "  fig.tight_layout(pad = 2)\n",
        "\n",
        "  xlim = 1 #Number of Inverter [1/m]\n",
        "  ylim = 2000 #Coil loss [W] \n",
        "  ax1.set_xlabel(r\"$Number\\ of\\ inverter\\ [1/m]$\", labelpad = x_label_pad)              # not shown\n",
        "  ax1.set_ylabel(r'$Coil loss [W]$', labelpad = y_label_pad) # not shown\n",
        "  x1 = np.arange(0, xlim + 0.1,0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "  plt_ax1 = ax1.scatter(accepted_n_inv_, accepted_coilloss, s=marker_size, c= color_list, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax1 , ax = ax1, label=r\"$B_{\\rm stray}~[\\rm \\mu T]$\")\n",
        "  ax1.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax1.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax1.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax1.axis([0,2, 0,5000])\n",
        "  ax1.tick_params(axis='x', pad=15)\n",
        "  # ax1.set_aspect('equal')\n",
        "\n",
        "\n",
        "\n",
        "  xlim = 100\n",
        "  ylim = 40\n",
        "  ax2.set_xlabel(r\"$B_{\\rm stray}~[\\rm \\mu T]$\", labelpad = x_label_pad)              # not shown\n",
        "  ax2.set_ylabel(r'$Coupling [\\%]$', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "\n",
        "  plt_ax2 = ax2.scatter(accepted_bstray, accepted_kdiff,s=marker_size, c= color_list, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax2 , ax = ax2, label=r\"$V_{PriCore}$\")\n",
        "  ax2.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax2.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax2.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax2.axis([0, 200, 0, 60])\n",
        "  ax2.tick_params(axis='x', pad=15)\n",
        "\n",
        "  # ax2.set_aspect('equal')\n",
        "\n",
        "  xlim = 3500\n",
        "  ylim = 30\n",
        "\n",
        "  ax3.set_xlabel(r\"$V_{SecCore}$\", labelpad = x_label_pad)              # not shown\n",
        "  ax3.set_ylabel(r'$P_{ave} [KW/M]$', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = ylim\n",
        "  y2 = ylim*10\n",
        "\n",
        "  ax3.scatter(accepted_v_sec_core, accpeted_pave,s=marker_size, c= color_list, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax3 , ax = ax3, label=r\"$V_{SecWind}$\")\n",
        "  ax3.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax3.plot([xlim, xlim], [ylim, ylim*10], 'r--', lw=0.5)  \n",
        "  ax3.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax3.axis([0, 5000, 0, 60])\n",
        "  ax3.tick_params(axis='x', pad=15)\n",
        "  # ax3.set_aspect('equal')\n",
        "\n",
        "\n",
        "  xlim = 750\n",
        "  ylim = 6000\n",
        "\n",
        "  ax4.set_xlabel(r\"$V_{SecWind}$\", labelpad = x_label_pad)              # not shown\n",
        "  ax4.set_ylabel(r'$V_{PriCore} $', labelpad = y_label_pad) # not shown\n",
        "\n",
        "  x1 = np.arange(0, xlim + 0.1, 0.1)\n",
        "  y1 = 0\n",
        "  y2 = ylim\n",
        "\n",
        "  ax4.scatter(accepted_v_sec_wind, accpeted_v_pri_core, s=marker_size, c= color_list, rasterized=True)\n",
        "  #fig.colorbar(mappable = plt_ax3 , ax = ax3, label=r\"$V_{SecWind}$\")\n",
        "  ax4.fill_between(x1, y1, y2 ,facecolor='r',alpha=0.3)\n",
        "  ax4.plot([xlim, xlim], [0, ylim], 'r--', lw=0.5)  \n",
        "  ax4.plot([0,xlim], [ylim, ylim], 'r--', lw=0.5) \n",
        "  ax4.axis([0, 2000, 0, 8000])\n",
        "  ax4.tick_params(axis='x', pad=15)\n",
        "\n",
        "  plt.suptitle(\"Epoch \" +str(epoch).zfill(5) + \"\\nFound \"+ str(len(accepted_bstray))+ \" solutions out of 1000 input\", y = 1.10)\n",
        "  plt.savefig(FULL_PATH + \"Solutions/\"+str(epoch).zfill(5) + \".png\")\n",
        "  # \"Epoch \"+str(epoch).zfill(5) + \"\\nFound \"+ str(len(accepted_bstray))+ \" solutions out of 1000 input\"\n",
        "  plt.clf()"
      ],
      "metadata": {
        "id": "Np8vWWu6PMob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Pel1PEhEvN"
      },
      "source": [
        "# Neural Network Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXzpQf5O1Nxk"
      },
      "outputs": [],
      "source": [
        "kdiffs = []\n",
        "bstrays = []\n",
        "paves = []\n",
        "coil_losses = []\n",
        "vpricores = []\n",
        "number_of_inverters_list = []\n",
        "vsec_cores = []\n",
        "accepted_solutions = []\n",
        "\n",
        "i=0\n",
        "combined_losses = []\n",
        "cumulative_solutions = [0]\n",
        "i = 1\n",
        "number_of_epochs = 5001\n",
        "max_solution = -float('inf')\n",
        "for epoch in range(number_of_epochs):\n",
        "    # Clear old gradients in the GP model\n",
        "    for param in gp_model.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "    # Create GP parameters from noise\n",
        "    noise = generate_noise(shape=(1000, 10), gaussian = GAUSSIAN)\n",
        "    gp = gp_model(noise)\n",
        "\n",
        "    # Unpack and filter GP parameters\n",
        "    a, lpx, lpy, ls, p, wp, ws, ip, np, ns, ys = scale_and_extract(gp)\n",
        "    gp_parameters = stack_parameters(a, lpx, lpy, ls, p, wp, ws, *ys)\n",
        "    extra_parameters = stack_parameters(ip, np, ns).transpose(0, 1)\n",
        "\n",
        "    V_PriCore, V_SecCore, V_PriWind,V_SecWind = core_losses(extra_parameters,gp_parameters)\n",
        "    new_number_of_inverters = number_of_inverters(gp_parameters)\n",
        "    \n",
        "    # Scale GP parameters - why?\n",
        "    min_x = torch.min(gp_parameters)\n",
        "    max_x = torch.max(gp_parameters)\n",
        "    gp_parameters = (gp_parameters - min_x) / (max_x - min_x)\n",
        "  \n",
        "    # Push GP parameters through MP model\n",
        "    mp_parameters = mp_model(gp_parameters)\n",
        "\n",
        "    # Scale MP parameters\n",
        "    y = torch.Tensor(df_mp.values).transpose(0, 1).to(\"cuda\")\n",
        "    min_y = torch.min(y, 1).values\n",
        "    max_y = torch.max(y, 1).values\n",
        "    mp_parameters = mp_parameters * (max_y - min_y) + min_y\n",
        "\n",
        "    k_parameters = mp_parameters.transpose(0, 1)[0:6]\n",
        "    l_parameters = mp_parameters.transpose(0, 1)[6:18]\n",
        "    b_parameters = mp_parameters.transpose(0, 1)[18:]\n",
        "\n",
        "    # Calculate losses\n",
        "    kdiff = kdiff_loss(k_parameters)\n",
        "    bstray = bstray_loss(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "    coilloss,pave = coil_loss_and_power_average(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "\n",
        "    kwargs = {}\n",
        "\n",
        "    kwargs[\"kdiff\"] = kdiff.clone().detach().cpu().numpy()\n",
        "    kwargs[\"pave\"] = pave.clone().detach().cpu().numpy()\n",
        "    kwargs[\"coilloss\"] = coilloss.clone().detach().cpu().numpy()\n",
        "    kwargs[\"bstray\"] = bstray.clone().detach().cpu().numpy()\n",
        "    kwargs[\"vpricore\"] = V_PriCore.clone().detach().cpu().numpy()\n",
        "    kwargs[\"vsecwind\"] = V_SecWind.clone().detach().cpu().numpy()\n",
        "    kwargs[\"n_inv\"] = new_number_of_inverters.clone().detach().cpu().numpy()\n",
        "    kwargs[\"vseccore\"] = V_SecCore.clone().detach().cpu().numpy()\n",
        "    kwargs[\"epoch\"] = epoch\n",
        "\n",
        "    accepted_solution_so_far = accepted_solution(**kwargs)\n",
        "\n",
        "    if epoch == 0:\n",
        "      accepted_solution_so_far = 0\n",
        "      \n",
        "    elif epoch%100 == 0:\n",
        "      accepted_solutions.append(accepted_solution_so_far)\n",
        "      cumulative_solutions.append(cumulative_solutions[i - 1] + accepted_solution_so_far)\n",
        "      i+=1\n",
        "      generate_solution_plot(**kwargs)\n",
        "\n",
        "    if max_solution < accepted_solution_so_far:\n",
        "      torch.save(gp_model.state_dict(), f\"./models/gp_model_{epoch:06}.pt\")\n",
        "      max_solution = accepted_solution_so_far\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "      print(\"Accepted Soluntions : \", accepted_solution_so_far)\n",
        "      plot_(**kwargs)\n",
        "    # Scale losses\n",
        "    #distance = distance_from_origin(kdiff, bstray, coilloss, V_SecCore, new_number_of_inverters) - distance_from_origin(pave)\n",
        "\n",
        "    # distance = distance_from_origin(kdiff,bstray,coilloss) \n",
        "    # distance.mean().backward()\n",
        "\n",
        "    new_kdiff = loss_function_relu(kdiff,.1502)\n",
        "    new_bstray = loss_function_relu(bstray, 41.9)\n",
        "    new_coil_loss = loss_function_relu(coilloss, 2000)\n",
        "    new_pave = loss_function_power_avg(pave)\n",
        "    new_number_of_inverters_ = loss_function_relu(new_number_of_inverters, 2)\n",
        "    new_vsec_core = loss_function_relu(V_SecCore, 1500)\n",
        "    new_v_pricore = loss_function_relu(V_PriCore, 6000)\n",
        "    new_v_secwind = loss_function_relu(V_SecWind, 750)\n",
        "\n",
        "    losses = [new_kdiff, new_bstray, new_coil_loss, new_pave, new_number_of_inverters_,new_vsec_core]\n",
        "\n",
        "    total_loss = torch.sum(losses[pair[0]]*losses[pair[1]] + losses[pair[2]] * losses[pair[3]] + losses[pair[4]] *losses[pair[5]])\n",
        "\n",
        "    # total_loss = torch.sum(new_kdiff + new_bstray + new_coil_loss + new_pave + new_number_of_inverters_\n",
        "    #                        + new_vsec_core + new_pave)# + new_v_pricore + new_v_secwind)\n",
        "    #total_loss = torch.sum(new_kdiff*new_bstray*new_v_pricore + new_coil_loss*new_number_of_inverters_*new_bstray + new_vsec_core*new_pave*new_v_secwind)\n",
        "\n",
        "    # total_loss = torch.sum(new_bstray*new_coil_loss + \n",
        "    #                        + new_coil_loss*new_number_of_inverters_ \n",
        "    #                        + new_number_of_inverters_*new_bstray)\n",
        "\n",
        "    # total_loss = torch.sum(new_kdiff*new_bstray + \\\n",
        "    #             new_coil_loss*new_number_of_inverters_ + new_number_of_inverters_*new_bstray + new_bstray*new_coil_loss + new_pave * new_vsec_core)\n",
        "    \n",
        "    # total_loss.backward()\n",
        "    # optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        # Store metrics for plotting or further logging\n",
        "        kdiffs.append(torch.mean(kdiff).cpu().data.numpy())\n",
        "        bstrays.append(torch.mean(bstray).cpu().data.numpy())\n",
        "        #vpricores.append(torch.mean(V_PriCore).cpu().data.numpy())\n",
        "        coil_losses.append(torch.mean(coilloss).cpu().data.numpy())\n",
        "        paves.append(torch.mean(pave).cpu().data.numpy())\n",
        "        number_of_inverters_list.append(torch.mean(new_number_of_inverters).cpu().data.numpy())\n",
        "        \n",
        "        print(f\"Epoch: {epoch:4d}\")\n",
        "        #print(f\"  Combined Loss:  {combined_losses[-1]:.10f}\")\n",
        "        print(f\"  Kdiff :         {100 * kdiffs[-1]:.4f}%\")\n",
        "        print(f\"  Bstray :        {bstrays[-1]:.4f}\")\n",
        "        print(f\"  Pave :        {paves[-1]:.4f}\")\n",
        "        print(f\"  Coilloss :        {coilloss[-1]:.4f}\")\n",
        "        print(f\"  Inverters :        {number_of_inverters_list[-1]:.4f}\")\n",
        "        #print(f\"  VPriCore :        {vpricores[-1]:.4f}\")\n",
        "\n",
        "        # Save model for further training or testing\n",
        "        #torch.save(gp_model.state_dict(), f\"./models/gp_model_{epoch:06}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([i*100 for i in range(len(cumulative_solutions))], cumulative_solutions)\n",
        "plt.ylim(0,1000)\n",
        "plt.xlim(0,5000)\n",
        "plt.title(\"Cumulative Solution Plot\", y = 1.10)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Total Solutions Found\")\n",
        "#plt.savefig(\"MeanLoss/\" + \"CumulativeSolution_MeanLoss\"+\".png\")\n",
        "plt.savefig(\"CumulativeSolution_MeanLoss.png\")"
      ],
      "metadata": {
        "id": "UDoVp8omA-Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mark = [i for i in range(0, number_of_epochs, 50)]\n",
        "# marked_points = [accepted_solutions[mark[i]] for i in range(len(mark))]\n",
        "accepted_solutions[0] = 0\n",
        "max_value = max(accepted_solutions)\n",
        "max_index = accepted_solutions.index(max_value)\n",
        "\n",
        "plt.plot([ i*100 for i in range(len(accepted_solutions))], accepted_solutions)\n",
        "\n",
        "# # plt.scatter(mark, marked_points, marker='o',color='y')\n",
        "# plt.scatter([max_index], [max_value], marker = 'o', color = 'r')\n",
        "\n",
        "# plt.annotate('Max number of solutions ('+ str(max_value)+') at epoch '+str(max_index), xy=(max_index,max_value), xycoords='data',\n",
        "#             xytext=(-90,60), textcoords='offset points',\n",
        "#             arrowprops=dict(arrowstyle='fancy',fc='0.2',\n",
        "#                             connectionstyle=\"angle3,angleA=45,angleB=90\"))\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Accepted solutions\")\n",
        "plt.savefig(FULL_PATH + \"soultions_per_epoch.png\")\n",
        "plt.clf()\n"
      ],
      "metadata": {
        "id": "uSdabxFwc2fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from os import walk\n",
        "\n",
        "# filenames = next(walk(\"images/\"), (None, None, []))[2]\n",
        "# filenames.sort(key=lambda f: int(f.split(\".\")[0]))\n",
        "# with imageio.get_writer('images/mygif.gif', mode='I') as writer:\n",
        "#   for filename in filenames:\n",
        "#       image = imageio.imread(\"images/\"+filename)\n",
        "#       writer.append_data(image)"
      ],
      "metadata": {
        "id": "WLzsIh64jlZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  noise = generate_noise(shape=(1000, 10), gaussian = GAUSSIAN)\n",
        "  # gp_model = GpModel(10).to(\"cuda\")\n",
        "  # gp_model.load_state_dict(torch.load(\"gp_model_000204.pt\"))\n",
        "  gp = gp_model(noise)\n",
        "  # Unpack and filter GP parameters\n",
        "  a, lpx, lpy, ls, p, wp, ws, ip, np, ns, ys = scale_and_extract(gp)\n",
        "  gp_parameters = stack_parameters(a, lpx, lpy, ls, p, wp, ws, *ys)\n",
        "  g = gp_parameters.clone()\n",
        "  #print(gp_parameters)\n",
        "  extra_parameters = stack_parameters(ip, np, ns).transpose(0, 1)\n",
        "  V_PriCore, V_SecCore, V_PriWind,V_SecWind = core_losses(extra_parameters,gp_parameters)\n",
        "  new_number_of_inverters = number_of_inverters(gp_parameters)\n",
        "  # Scale GP parameters - why?\n",
        "  min_x = torch.min(gp_parameters)\n",
        "  max_x = torch.max(gp_parameters)\n",
        "  gp_parameters = (gp_parameters - min_x) / (max_x - min_x)\n",
        "\n",
        "  # Push GP parameters through MP model\n",
        "  mp_parameters = mp_model(gp_parameters)\n",
        "\n",
        "  # Scale MP parameters\n",
        "  y = torch.Tensor(df_mp.values).transpose(0, 1).to(\"cuda\")\n",
        "  min_y = torch.min(y, 1).values\n",
        "  max_y = torch.max(y, 1).values\n",
        "  mp_parameters = mp_parameters * (max_y - min_y) + min_y\n",
        "\n",
        "  k_parameters = mp_parameters.transpose(0, 1)[0:6]\n",
        "  l_parameters = mp_parameters.transpose(0, 1)[6:18]\n",
        "  b_parameters = mp_parameters.transpose(0, 1)[18:]\n",
        "\n",
        "  # Calculate losses\n",
        "  kdiff = kdiff_loss(k_parameters)\n",
        "  bstray = bstray_loss(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "  coilloss,pave = coil_loss_and_power_average(k_parameters, l_parameters, b_parameters, extra_parameters)\n",
        "  kwargs = {}\n",
        "\n",
        "  kwargs[\"kdiff\"] = kdiff.clone().detach().cpu().numpy()\n",
        "  kwargs[\"pave\"] = pave.clone().detach().cpu().numpy()\n",
        "  kwargs[\"coilloss\"] = coilloss.clone().detach().cpu().numpy()\n",
        "  kwargs[\"bstray\"] = bstray.clone().detach().cpu().numpy()\n",
        "  kwargs[\"vpricore\"] = V_PriCore.clone().detach().cpu().numpy()\n",
        "  kwargs[\"vsecwind\"] = V_SecWind.clone().detach().cpu().numpy()\n",
        "  kwargs[\"n_inv\"] = new_number_of_inverters.clone().detach().cpu().numpy()\n",
        "  kwargs[\"vseccore\"] = V_SecCore.clone().detach().cpu().numpy()\n",
        "  kwargs[\"epoch\"] = 1\n",
        "\n",
        "  #plot_(**kwargs)\n",
        "\n",
        "  print(accepted_solution(**kwargs))"
      ],
      "metadata": {
        "id": "eA_Mwz2cdxlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min(kwargs[\"vsecwind\"])"
      ],
      "metadata": {
        "id": "K1gJVjQdwaS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_solution_plot(**kwargs)"
      ],
      "metadata": {
        "id": "waSdXH0ZL51R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATQnvWclZaID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from prettytable import PrettyTable\n",
        "# t = PrettyTable(['Number of Inverters [1/m]', 'Coilloss [W]', 'Bstray[uT]', 'Coupling [%]', 'V_Sec_Core [cm3]', 'Power Average [kW/m'])\n",
        "# for i in range(len(accepted_n_inv_)):\n",
        "#   t.add_row([accepted_n_inv_[i], accepted_coilloss[i],accepted_bstray[i],accepted_kdiff[i],accepted_v_sec_core[i], accpeted_pave[i]])\n",
        "# print(t)"
      ],
      "metadata": {
        "id": "TDUoIL7QQMkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}