{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iZN2u5WKRFqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3719787-8dd0-48aa-c154-61151f20aa8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f693d825a50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torch import nn \n",
        "from torch import sigmoid\n",
        "from torch import atan\n",
        "from torch import tanh\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "seed = 7777\n",
        "random.seed(seed) \n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bse1wsKN1NxY"
      },
      "outputs": [],
      "source": [
        "lpy_min = 50 #mm\n",
        "lpy_max = 2050 #mm\n",
        "lpx_min = 50 #mm\n",
        "lpx_max = 650 #mm\n",
        "wp_min = 25 # mm\n",
        "wp_max = 325 # mm\n",
        "a_min = 0 # mm\n",
        "a_max = 200 # mm\n",
        "p_min = 0 # mm\n",
        "p_max = 200 # mm\n",
        "ls_min = 50 # mm\n",
        "ls_max = 450 # mm\n",
        "ws_min = 25 # mm\n",
        "ws_max = 225 # mm\n",
        "# Ip_min = 50 # A rms\n",
        "# Ip_max = 200 # A rms\n",
        "# Np_min = 4 #turn\n",
        "# Np_max = 10 #turn\n",
        "# Ns_min = 4 #turn\n",
        "# Ns_max = 10 #turn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B-TMPJtCKIM6"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module): # Design your model using class\n",
        "    def __init__(self):    \n",
        "        super(Model, self).__init__() #In the constructor, we instantiate nn.Linear module.\n",
        "        self.linear1 = nn.Linear(12, 100, bias=True).cuda() # nn.Linear(<input size> ,<output size>)\n",
        "        self.linear2 = nn.Linear(100, 100, bias=True).cuda()\n",
        "        self.linear3 = nn.Linear(100, 42, bias=True).cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = atan(self.linear1(x))\n",
        "        x = atan(self.linear2(x))\n",
        "        x = atan(self.linear2(x))\n",
        "        y_pred = self.linear3(x)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g9oqBtYCRR_c"
      },
      "outputs": [],
      "source": [
        "model = Model() # our model\n",
        "model.load_state_dict(torch.load('saved_model_state.pt'))\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dMoXnTFV8U1P"
      },
      "outputs": [],
      "source": [
        "def generate_noise(a, b):\n",
        "    low,high = 0, 1  # range of uniform distribution\n",
        "\n",
        "    return torch.distributions.uniform.Uniform(low,high).sample([a,b]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "z9cggAl1BGHo"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dense_layer = nn.Linear(int(input_length), 128).cuda()\n",
        "        self.dense_layer1 = nn.Linear(128, 256).cuda()\n",
        "        self.dense_layer2 = nn.Linear(256, 512).cuda()\n",
        "        self.dense_layer3 = nn.Linear(512, 1024).cuda()\n",
        "        self.dense_layer4 = nn.Linear(1024, 512).cuda()\n",
        "        self.dense_layer5 = nn.Linear(512, 256).cuda()\n",
        "        self.dense_layer6 = nn.Linear(256, 128).cuda()\n",
        "        self.dense_layer7 = nn.Linear(128, int(input_length)).cuda()\n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = atan(self.dense_layer(x))\n",
        "        x = atan(self.dense_layer1(x))\n",
        "        x = atan(self.dense_layer2(x))\n",
        "        x = atan(self.dense_layer3(x))\n",
        "        x = atan(self.dense_layer4(x))\n",
        "        x = atan(self.dense_layer5(x))\n",
        "        x = atan(self.dense_layer6(x))\n",
        "        x = self.activation(self.dense_layer7(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vuPxzX7KuP2l"
      },
      "outputs": [],
      "source": [
        "generator = Generator(7)\n",
        "generator.requires_grad_= True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lmtwMfOB20K4"
      },
      "outputs": [],
      "source": [
        "def scaler(value, min , max):\n",
        "    return value * (max - min) + min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "brlwMfzj1Nxh"
      },
      "outputs": [],
      "source": [
        "@torch.jit.script\n",
        "def linspace(start: torch.Tensor, stop: torch.Tensor, num: int):\n",
        "    \"\"\"\n",
        "    Creates a tensor of shape [num, *start.shape] whose values are evenly spaced from start to end, inclusive.\n",
        "    Replicates but the multi-dimensional bahaviour of numpy.linspace in PyTorch.\n",
        "    \"\"\"\n",
        "    # create a tensor of 'num' steps from 0 to 1\n",
        "    steps = torch.arange(num, dtype=torch.float32, device=start.device) / (num - 1)\n",
        "    \n",
        "    # reshape the 'steps' tensor to [-1, *([1]*start.ndim)] to allow for broadcastings\n",
        "    # - using 'steps.reshape([-1, *([1]*start.ndim)])' would be nice here but torchscript\n",
        "    #   \"cannot statically infer the expected size of a list in this contex\", hence the code below\n",
        "    for i in range(start.ndim):\n",
        "        steps = steps.unsqueeze(-1)\n",
        "    \n",
        "    # the output starts at 'start' and increments until 'stop' in each dimension\n",
        "    out = start[None] + steps*(stop - start)[None]\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xloGE25R8Jtm"
      },
      "outputs": [],
      "source": [
        "def scale_and_extract(arr):\n",
        "    print(arr[0])\n",
        "    scaler_min = torch.tensor([50., 50., 25., 0., 0., 50., 25.], requires_grad=True, device=\"cuda\")\n",
        "    scaler_max = torch.tensor([2050., 650., 325., 200., 200., 450., 225.], requires_grad=True, device=\"cuda\")\n",
        "    arr = scaler(arr, scaler_min, scaler_max)\n",
        "    print(arr[0])\n",
        "    y0_i = (arr[:,0] + arr[:,2]) / 2\n",
        "    y1_i = (3/2 * arr[:,0]) + (5/2 * arr[:,2]) + (2 * arr[:,3]) + (arr[:,4])\n",
        "\n",
        "    ys_min = (y1_i)\n",
        "    ys_max = (y1_i + (y1_i - y0_i) / 2)\n",
        "    \n",
        "    ys = linspace(ys_min, ys_max, num = 5)\n",
        "    ys = torch.transpose(ys, 0, 1)\n",
        "\n",
        "    return torch.cat([arr, ys], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7be3y_pG1Nxj"
      },
      "outputs": [],
      "source": [
        "TRAINING = 50000\n",
        "learning_rate = 3e-4\n",
        "optimizer = torch.optim.Adam(generator.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXzpQf5O1Nxk",
        "outputId": "21e3211c-24e9-4e07-d348-f56572bfc241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7594, 0.7356, 0.2556,  ..., 0.2930, 0.9439, 0.6944],\n",
            "        [0.3204, 0.8819, 0.3080,  ..., 0.4136, 0.0314, 0.1652],\n",
            "        [0.3942, 0.8906, 0.9813,  ..., 0.0291, 0.8477, 0.6556],\n",
            "        ...,\n",
            "        [0.9581, 0.8677, 0.5728,  ..., 0.0173, 0.4631, 0.1861],\n",
            "        [0.4225, 0.7138, 0.8621,  ..., 0.6353, 0.8093, 0.3532],\n",
            "        [0.5751, 0.7198, 0.5447,  ..., 0.8842, 0.8882, 0.6736]],\n",
            "       device='cuda:0')\n",
            "tensor([9.9997e-01, 7.3271e-01, 6.1664e-01, 5.8002e-01, 6.7957e-06, 9.9999e-01,\n",
            "        9.9998e-01], device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([2.0499e+03, 4.8963e+02, 2.0999e+02, 1.1600e+02, 1.3591e-03, 4.5000e+02,\n",
            "        2.2500e+02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([2.0499e+03, 4.8963e+02, 2.0999e+02, 1.1600e+02, 1.3591e-03, 4.5000e+02,\n",
            "        2.2500e+02, 3.8319e+03, 4.1696e+03, 4.5074e+03, 4.8451e+03, 5.1829e+03],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "for i in range(TRAINING):\n",
        "    \n",
        "    # zero out the parameter gradients\n",
        "    # self.optimizer.zero_grad() is slow\n",
        "    for param in generator.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "    noise = generate_noise(10000, 7)\n",
        "    print(noise)\n",
        "    GP = generator(noise)\n",
        "    \n",
        "    scaled_array = scale_and_extract(GP)\n",
        "    print(scaled_array[0])\n",
        "    break\n",
        "    MP = model(scaled_array)\n",
        "    \n",
        "    kdiff = MP[:, 0] - MP[:, 5]\n",
        "    kdiff = abs(kdiff / MP[:, 0])\n",
        "    kdiff = torch.mean(kdiff)\n",
        "    \n",
        "    kdiff.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 2500 == 0:\n",
        "        print(f\"Epoch: {i:4d} | Coupling: {100 * kdiff:.3f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7vYhBD31Nxl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "optimization_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}